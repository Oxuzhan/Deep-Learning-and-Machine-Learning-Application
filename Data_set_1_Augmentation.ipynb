{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import skimage.exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creation of the set of images\n",
    "\n",
    "folder_path = r'D:\\Mines Paris-PSL\\S4E\\Machine learning\\Exercises\\Exercise_3\\photo'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over all files and subfolders in the folder\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        # Check if the file is an image (you can adjust the condition based on your image file extensions)\n",
    "        if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            # Access the image file path\n",
    "            image_path = os.path.join(root, file)\n",
    "\n",
    "            image = plt.imread(image_path)\n",
    "\n",
    "            images.append(image)\n",
    "            labels.append(os.path.basename(root))\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITHOUT DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lenet implementation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def create_LeNet_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer 1: Convolutional layer with 6 filters, 5x5 kernel, and ReLU activation\n",
    "    model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 2: Convolutional layer with 16 filters, 5x5 kernel, and ReLU activation\n",
    "    model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten the feature maps\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Layer 3: Fully connected layer with 120 units and ReLU activation\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "\n",
    "    # Layer 4: Fully connected layer with 84 units and ReLU activation\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "\n",
    "    # Layer 5: Output layer with 'num_classes' units and softmax activation\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 6s 138ms/step - loss: 3.0587 - accuracy: 0.2315 - val_loss: 2.1358 - val_accuracy: 0.2748\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 1.9067 - accuracy: 0.3427 - val_loss: 2.0722 - val_accuracy: 0.2881\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 1.5973 - accuracy: 0.4539 - val_loss: 2.0706 - val_accuracy: 0.3013\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 1.2135 - accuracy: 0.5826 - val_loss: 1.9900 - val_accuracy: 0.3444\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.7993 - accuracy: 0.7386 - val_loss: 2.2951 - val_accuracy: 0.3709\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.5202 - accuracy: 0.8390 - val_loss: 2.2137 - val_accuracy: 0.4106\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.2822 - accuracy: 0.9137 - val_loss: 2.5716 - val_accuracy: 0.4205\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.1634 - accuracy: 0.9627 - val_loss: 3.0125 - val_accuracy: 0.4536\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.1353 - accuracy: 0.9660 - val_loss: 2.9666 - val_accuracy: 0.4205\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.2080 - accuracy: 0.9436 - val_loss: 3.0608 - val_accuracy: 0.4272\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.1226 - accuracy: 0.9734 - val_loss: 3.2838 - val_accuracy: 0.4238\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.0708 - accuracy: 0.9842 - val_loss: 3.2858 - val_accuracy: 0.4437\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.0805 - accuracy: 0.9851 - val_loss: 3.5820 - val_accuracy: 0.4305\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.0382 - accuracy: 0.9917 - val_loss: 3.7718 - val_accuracy: 0.4536\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.0130 - accuracy: 0.9983 - val_loss: 3.8833 - val_accuracy: 0.4437\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 4.0809 - val_accuracy: 0.4603\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.2357 - val_accuracy: 0.4536\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.3711 - val_accuracy: 0.4702\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.4785 - val_accuracy: 0.4768\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.5899 - val_accuracy: 0.4735\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.6818 - val_accuracy: 0.4768\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.7761 - val_accuracy: 0.4834\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 8.5550e-04 - accuracy: 1.0000 - val_loss: 4.8425 - val_accuracy: 0.4868\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 6.5392e-04 - accuracy: 1.0000 - val_loss: 4.8993 - val_accuracy: 0.4801\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 5.2980e-04 - accuracy: 1.0000 - val_loss: 4.9510 - val_accuracy: 0.4801\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 4.4774e-04 - accuracy: 1.0000 - val_loss: 5.0005 - val_accuracy: 0.4801\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 3.6731e-04 - accuracy: 1.0000 - val_loss: 5.0398 - val_accuracy: 0.4868\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 3.2959e-04 - accuracy: 1.0000 - val_loss: 5.0841 - val_accuracy: 0.4834\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 2.8362e-04 - accuracy: 1.0000 - val_loss: 5.1166 - val_accuracy: 0.4834\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 2.5102e-04 - accuracy: 1.0000 - val_loss: 5.1563 - val_accuracy: 0.4801\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 2.2837e-04 - accuracy: 1.0000 - val_loss: 5.1872 - val_accuracy: 0.4834\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 2.0421e-04 - accuracy: 1.0000 - val_loss: 5.2235 - val_accuracy: 0.4801\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 1.8487e-04 - accuracy: 1.0000 - val_loss: 5.2464 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 1.6873e-04 - accuracy: 1.0000 - val_loss: 5.2731 - val_accuracy: 0.4868\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.5516e-04 - accuracy: 1.0000 - val_loss: 5.3031 - val_accuracy: 0.4834\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 1.4320e-04 - accuracy: 1.0000 - val_loss: 5.3281 - val_accuracy: 0.4801\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 1.3251e-04 - accuracy: 1.0000 - val_loss: 5.3480 - val_accuracy: 0.4834\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.2338e-04 - accuracy: 1.0000 - val_loss: 5.3764 - val_accuracy: 0.4834\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 1.1520e-04 - accuracy: 1.0000 - val_loss: 5.3959 - val_accuracy: 0.4834\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.0711e-04 - accuracy: 1.0000 - val_loss: 5.4210 - val_accuracy: 0.4834\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.0050e-04 - accuracy: 1.0000 - val_loss: 5.4402 - val_accuracy: 0.4834\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 9.4186e-05 - accuracy: 1.0000 - val_loss: 5.4605 - val_accuracy: 0.4834\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 8.8607e-05 - accuracy: 1.0000 - val_loss: 5.4834 - val_accuracy: 0.4834\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 8.3673e-05 - accuracy: 1.0000 - val_loss: 5.5023 - val_accuracy: 0.4801\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 7.8839e-05 - accuracy: 1.0000 - val_loss: 5.5222 - val_accuracy: 0.4801\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 7.4620e-05 - accuracy: 1.0000 - val_loss: 5.5410 - val_accuracy: 0.4801\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 7.0518e-05 - accuracy: 1.0000 - val_loss: 5.5583 - val_accuracy: 0.4801\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 6.7042e-05 - accuracy: 1.0000 - val_loss: 5.5778 - val_accuracy: 0.4801\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 6.3492e-05 - accuracy: 1.0000 - val_loss: 5.5924 - val_accuracy: 0.4801\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 6.0603e-05 - accuracy: 1.0000 - val_loss: 5.6072 - val_accuracy: 0.4801\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 5.7450e-05 - accuracy: 1.0000 - val_loss: 5.6269 - val_accuracy: 0.4801\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 5.4801e-05 - accuracy: 1.0000 - val_loss: 5.6419 - val_accuracy: 0.4768\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 5.2408e-05 - accuracy: 1.0000 - val_loss: 5.6592 - val_accuracy: 0.4801\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 4.9844e-05 - accuracy: 1.0000 - val_loss: 5.6744 - val_accuracy: 0.4768\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 4.7603e-05 - accuracy: 1.0000 - val_loss: 5.6891 - val_accuracy: 0.4768\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 4.5581e-05 - accuracy: 1.0000 - val_loss: 5.7044 - val_accuracy: 0.4735\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 4.3627e-05 - accuracy: 1.0000 - val_loss: 5.7191 - val_accuracy: 0.4735\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 4.1716e-05 - accuracy: 1.0000 - val_loss: 5.7352 - val_accuracy: 0.4735\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 3.9955e-05 - accuracy: 1.0000 - val_loss: 5.7493 - val_accuracy: 0.4702\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 3.8312e-05 - accuracy: 1.0000 - val_loss: 5.7639 - val_accuracy: 0.4702\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 3.6729e-05 - accuracy: 1.0000 - val_loss: 5.7797 - val_accuracy: 0.4768\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 3.5301e-05 - accuracy: 1.0000 - val_loss: 5.7935 - val_accuracy: 0.4735\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 3.3979e-05 - accuracy: 1.0000 - val_loss: 5.8064 - val_accuracy: 0.4768\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 3.2533e-05 - accuracy: 1.0000 - val_loss: 5.8176 - val_accuracy: 0.4768\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 3.1285e-05 - accuracy: 1.0000 - val_loss: 5.8304 - val_accuracy: 0.4768\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 3.0306e-05 - accuracy: 1.0000 - val_loss: 5.8462 - val_accuracy: 0.4768\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 2.8997e-05 - accuracy: 1.0000 - val_loss: 5.8587 - val_accuracy: 0.4768\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 2.7978e-05 - accuracy: 1.0000 - val_loss: 5.8709 - val_accuracy: 0.4735\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 2.6933e-05 - accuracy: 1.0000 - val_loss: 5.8841 - val_accuracy: 0.4735\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 2.5957e-05 - accuracy: 1.0000 - val_loss: 5.8969 - val_accuracy: 0.4735\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 2.5072e-05 - accuracy: 1.0000 - val_loss: 5.9071 - val_accuracy: 0.4735\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 2.4189e-05 - accuracy: 1.0000 - val_loss: 5.9201 - val_accuracy: 0.4735\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 2.3392e-05 - accuracy: 1.0000 - val_loss: 5.9334 - val_accuracy: 0.4735\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 2.2562e-05 - accuracy: 1.0000 - val_loss: 5.9442 - val_accuracy: 0.4735\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 2.1790e-05 - accuracy: 1.0000 - val_loss: 5.9561 - val_accuracy: 0.4735\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 2.1060e-05 - accuracy: 1.0000 - val_loss: 5.9688 - val_accuracy: 0.4735\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 2.0385e-05 - accuracy: 1.0000 - val_loss: 5.9788 - val_accuracy: 0.4768\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 1.9720e-05 - accuracy: 1.0000 - val_loss: 5.9922 - val_accuracy: 0.4768\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.9072e-05 - accuracy: 1.0000 - val_loss: 6.0020 - val_accuracy: 0.4768\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 1.8462e-05 - accuracy: 1.0000 - val_loss: 6.0140 - val_accuracy: 0.4768\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 1.7862e-05 - accuracy: 1.0000 - val_loss: 6.0256 - val_accuracy: 0.4768\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.7327e-05 - accuracy: 1.0000 - val_loss: 6.0368 - val_accuracy: 0.4768\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 1.6762e-05 - accuracy: 1.0000 - val_loss: 6.0472 - val_accuracy: 0.4768\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 1.6256e-05 - accuracy: 1.0000 - val_loss: 6.0582 - val_accuracy: 0.4768\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.5730e-05 - accuracy: 1.0000 - val_loss: 6.0711 - val_accuracy: 0.4768\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.5238e-05 - accuracy: 1.0000 - val_loss: 6.0831 - val_accuracy: 0.4768\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.4784e-05 - accuracy: 1.0000 - val_loss: 6.0924 - val_accuracy: 0.4801\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.4349e-05 - accuracy: 1.0000 - val_loss: 6.1036 - val_accuracy: 0.4801\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 1.3938e-05 - accuracy: 1.0000 - val_loss: 6.1155 - val_accuracy: 0.4801\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.3495e-05 - accuracy: 1.0000 - val_loss: 6.1247 - val_accuracy: 0.4801\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 1.3112e-05 - accuracy: 1.0000 - val_loss: 6.1359 - val_accuracy: 0.4801\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.2730e-05 - accuracy: 1.0000 - val_loss: 6.1460 - val_accuracy: 0.4735\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.2353e-05 - accuracy: 1.0000 - val_loss: 6.1579 - val_accuracy: 0.4768\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 1.1988e-05 - accuracy: 1.0000 - val_loss: 6.1674 - val_accuracy: 0.4768\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 1.1662e-05 - accuracy: 1.0000 - val_loss: 6.1774 - val_accuracy: 0.4735\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 1.1321e-05 - accuracy: 1.0000 - val_loss: 6.1875 - val_accuracy: 0.4768\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.1008e-05 - accuracy: 1.0000 - val_loss: 6.1980 - val_accuracy: 0.4768\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.0705e-05 - accuracy: 1.0000 - val_loss: 6.2072 - val_accuracy: 0.4768\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 1.0398e-05 - accuracy: 1.0000 - val_loss: 6.2183 - val_accuracy: 0.4768\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 1.0112e-05 - accuracy: 1.0000 - val_loss: 6.2284 - val_accuracy: 0.4768\n",
      "10/10 [==============================] - 0s 31ms/step\n",
      "Fold 2\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 5s 115ms/step - loss: 29.7308 - accuracy: 0.2340 - val_loss: 2.2181 - val_accuracy: 0.2947\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.6360 - accuracy: 0.4622 - val_loss: 1.7181 - val_accuracy: 0.4272\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 1.1194 - accuracy: 0.6432 - val_loss: 1.5714 - val_accuracy: 0.4768\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 0.7590 - accuracy: 0.7884 - val_loss: 1.5132 - val_accuracy: 0.4868\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 0.4577 - accuracy: 0.8805 - val_loss: 1.5585 - val_accuracy: 0.5364\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.2749 - accuracy: 0.9378 - val_loss: 1.6295 - val_accuracy: 0.5530\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 0.1511 - accuracy: 0.9826 - val_loss: 1.6351 - val_accuracy: 0.5563\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0769 - accuracy: 0.9959 - val_loss: 1.8136 - val_accuracy: 0.5298\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0411 - accuracy: 0.9992 - val_loss: 2.0124 - val_accuracy: 0.5563\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.0063 - val_accuracy: 0.5530\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.1559 - val_accuracy: 0.5695\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.2087 - val_accuracy: 0.5662\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.3181 - val_accuracy: 0.5530\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.4577 - val_accuracy: 0.5662\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.4981 - val_accuracy: 0.5728\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.5210 - val_accuracy: 0.5695\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.5820 - val_accuracy: 0.5728\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.6847 - val_accuracy: 0.5795\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6964 - val_accuracy: 0.5861\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7396 - val_accuracy: 0.5894\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.5861\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.8362 - val_accuracy: 0.5828\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8382 - val_accuracy: 0.5894\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8796 - val_accuracy: 0.5828\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 9.3074e-04 - accuracy: 1.0000 - val_loss: 2.9238 - val_accuracy: 0.5894\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 8.3723e-04 - accuracy: 1.0000 - val_loss: 2.9604 - val_accuracy: 0.5861\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 7.5955e-04 - accuracy: 1.0000 - val_loss: 2.9930 - val_accuracy: 0.5828\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 6.9557e-04 - accuracy: 1.0000 - val_loss: 3.0163 - val_accuracy: 0.5894\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 6.3244e-04 - accuracy: 1.0000 - val_loss: 3.0484 - val_accuracy: 0.5894\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 5.8109e-04 - accuracy: 1.0000 - val_loss: 3.0738 - val_accuracy: 0.5894\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 5.3259e-04 - accuracy: 1.0000 - val_loss: 3.1047 - val_accuracy: 0.5894\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 4.9492e-04 - accuracy: 1.0000 - val_loss: 3.1324 - val_accuracy: 0.5894\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 4.5484e-04 - accuracy: 1.0000 - val_loss: 3.1432 - val_accuracy: 0.5894\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 4.2481e-04 - accuracy: 1.0000 - val_loss: 3.1617 - val_accuracy: 0.5927\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 3.9192e-04 - accuracy: 1.0000 - val_loss: 3.1936 - val_accuracy: 0.5960\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 3.6562e-04 - accuracy: 1.0000 - val_loss: 3.2216 - val_accuracy: 0.5894\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 5s 117ms/step - loss: 3.4191e-04 - accuracy: 1.0000 - val_loss: 3.2347 - val_accuracy: 0.5960\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 3.1969e-04 - accuracy: 1.0000 - val_loss: 3.2541 - val_accuracy: 0.5960\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 2.9845e-04 - accuracy: 1.0000 - val_loss: 3.2818 - val_accuracy: 0.5927\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 2.8068e-04 - accuracy: 1.0000 - val_loss: 3.2922 - val_accuracy: 0.5894\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 2.6198e-04 - accuracy: 1.0000 - val_loss: 3.3117 - val_accuracy: 0.5960\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 2.4638e-04 - accuracy: 1.0000 - val_loss: 3.3371 - val_accuracy: 0.5894\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 2.3186e-04 - accuracy: 1.0000 - val_loss: 3.3564 - val_accuracy: 0.5861\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 2.2030e-04 - accuracy: 1.0000 - val_loss: 3.3669 - val_accuracy: 0.5894\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 2.0749e-04 - accuracy: 1.0000 - val_loss: 3.3918 - val_accuracy: 0.5828\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 1.9623e-04 - accuracy: 1.0000 - val_loss: 3.4016 - val_accuracy: 0.5861\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.8468e-04 - accuracy: 1.0000 - val_loss: 3.4233 - val_accuracy: 0.5927\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.7484e-04 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.5894\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.6601e-04 - accuracy: 1.0000 - val_loss: 3.4649 - val_accuracy: 0.5927\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.5718e-04 - accuracy: 1.0000 - val_loss: 3.4697 - val_accuracy: 0.5894\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 1.4879e-04 - accuracy: 1.0000 - val_loss: 3.4895 - val_accuracy: 0.5894\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.4171e-04 - accuracy: 1.0000 - val_loss: 3.5063 - val_accuracy: 0.5894\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.3459e-04 - accuracy: 1.0000 - val_loss: 3.5216 - val_accuracy: 0.5927\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.2832e-04 - accuracy: 1.0000 - val_loss: 3.5387 - val_accuracy: 0.5894\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.2237e-04 - accuracy: 1.0000 - val_loss: 3.5627 - val_accuracy: 0.5927\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.1666e-04 - accuracy: 1.0000 - val_loss: 3.5820 - val_accuracy: 0.5894\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 1.1057e-04 - accuracy: 1.0000 - val_loss: 3.5912 - val_accuracy: 0.5861\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.0531e-04 - accuracy: 1.0000 - val_loss: 3.6106 - val_accuracy: 0.5927\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 1.0072e-04 - accuracy: 1.0000 - val_loss: 3.6278 - val_accuracy: 0.5927\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 9.5957e-05 - accuracy: 1.0000 - val_loss: 3.6438 - val_accuracy: 0.5894\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 9.1486e-05 - accuracy: 1.0000 - val_loss: 3.6611 - val_accuracy: 0.5894\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 8.7461e-05 - accuracy: 1.0000 - val_loss: 3.6705 - val_accuracy: 0.5861\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 8.3546e-05 - accuracy: 1.0000 - val_loss: 3.6888 - val_accuracy: 0.5861\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 7.9934e-05 - accuracy: 1.0000 - val_loss: 3.7048 - val_accuracy: 0.5861\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 7.6581e-05 - accuracy: 1.0000 - val_loss: 3.7175 - val_accuracy: 0.5828\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 7.3197e-05 - accuracy: 1.0000 - val_loss: 3.7313 - val_accuracy: 0.5861\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 6.9994e-05 - accuracy: 1.0000 - val_loss: 3.7460 - val_accuracy: 0.5861\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 6.7065e-05 - accuracy: 1.0000 - val_loss: 3.7629 - val_accuracy: 0.5894\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 6.4362e-05 - accuracy: 1.0000 - val_loss: 3.7714 - val_accuracy: 0.5861\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 6.1671e-05 - accuracy: 1.0000 - val_loss: 3.7870 - val_accuracy: 0.5861\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 5.9135e-05 - accuracy: 1.0000 - val_loss: 3.7920 - val_accuracy: 0.5861\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 5.6975e-05 - accuracy: 1.0000 - val_loss: 3.7979 - val_accuracy: 0.5861\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 5.4882e-05 - accuracy: 1.0000 - val_loss: 3.8119 - val_accuracy: 0.5861\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 5.2670e-05 - accuracy: 1.0000 - val_loss: 3.8229 - val_accuracy: 0.5861\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 5.0594e-05 - accuracy: 1.0000 - val_loss: 3.8301 - val_accuracy: 0.5828\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 4.8780e-05 - accuracy: 1.0000 - val_loss: 3.8470 - val_accuracy: 0.5861\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 4.6891e-05 - accuracy: 1.0000 - val_loss: 3.8627 - val_accuracy: 0.5861\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 4.5153e-05 - accuracy: 1.0000 - val_loss: 3.8695 - val_accuracy: 0.5894\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 4.3639e-05 - accuracy: 1.0000 - val_loss: 3.8838 - val_accuracy: 0.5861\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 6s 151ms/step - loss: 4.1934e-05 - accuracy: 1.0000 - val_loss: 3.8888 - val_accuracy: 0.5894\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 5s 138ms/step - loss: 4.0438e-05 - accuracy: 1.0000 - val_loss: 3.9068 - val_accuracy: 0.5894\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 3.9145e-05 - accuracy: 1.0000 - val_loss: 3.9089 - val_accuracy: 0.5861\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 3.7790e-05 - accuracy: 1.0000 - val_loss: 3.9234 - val_accuracy: 0.5894\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 3.6342e-05 - accuracy: 1.0000 - val_loss: 3.9377 - val_accuracy: 0.5861\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 3.5181e-05 - accuracy: 1.0000 - val_loss: 3.9423 - val_accuracy: 0.5894\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 3.3935e-05 - accuracy: 1.0000 - val_loss: 3.9538 - val_accuracy: 0.5894\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 3.2862e-05 - accuracy: 1.0000 - val_loss: 3.9715 - val_accuracy: 0.5861\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 3.1669e-05 - accuracy: 1.0000 - val_loss: 3.9729 - val_accuracy: 0.5894\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 3.0686e-05 - accuracy: 1.0000 - val_loss: 3.9879 - val_accuracy: 0.5894\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 2.9797e-05 - accuracy: 1.0000 - val_loss: 3.9949 - val_accuracy: 0.5894\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.8696e-05 - accuracy: 1.0000 - val_loss: 4.0046 - val_accuracy: 0.5894\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 2.7726e-05 - accuracy: 1.0000 - val_loss: 4.0128 - val_accuracy: 0.5894\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 2.6808e-05 - accuracy: 1.0000 - val_loss: 4.0299 - val_accuracy: 0.5927\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.5960e-05 - accuracy: 1.0000 - val_loss: 4.0383 - val_accuracy: 0.5927\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 2.5139e-05 - accuracy: 1.0000 - val_loss: 4.0442 - val_accuracy: 0.5927\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 2.4335e-05 - accuracy: 1.0000 - val_loss: 4.0533 - val_accuracy: 0.5927\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 2.3577e-05 - accuracy: 1.0000 - val_loss: 4.0609 - val_accuracy: 0.5927\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.2798e-05 - accuracy: 1.0000 - val_loss: 4.0756 - val_accuracy: 0.5960\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 2.2097e-05 - accuracy: 1.0000 - val_loss: 4.0800 - val_accuracy: 0.5960\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 2.1397e-05 - accuracy: 1.0000 - val_loss: 4.0963 - val_accuracy: 0.5927\n",
      "10/10 [==============================] - 0s 34ms/step\n",
      "Fold 3\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 21.3550 - accuracy: 0.1575 - val_loss: 2.1850 - val_accuracy: 0.2492\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 1.7702 - accuracy: 0.4187 - val_loss: 2.0049 - val_accuracy: 0.3023\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.0475 - accuracy: 0.6625 - val_loss: 1.8531 - val_accuracy: 0.4352\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.4571 - accuracy: 0.8582 - val_loss: 2.1340 - val_accuracy: 0.4518\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.2139 - accuracy: 0.9469 - val_loss: 2.5499 - val_accuracy: 0.4419\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0914 - accuracy: 0.9801 - val_loss: 2.7637 - val_accuracy: 0.5050\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0715 - accuracy: 0.9851 - val_loss: 2.6505 - val_accuracy: 0.4618\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0494 - accuracy: 0.9892 - val_loss: 3.3594 - val_accuracy: 0.4950\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0342 - accuracy: 0.9892 - val_loss: 3.4046 - val_accuracy: 0.5150\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0450 - accuracy: 0.9909 - val_loss: 3.1855 - val_accuracy: 0.4884\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 3.4707 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 3.5711 - val_accuracy: 0.5017\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 3.3645 - val_accuracy: 0.4983\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0292 - accuracy: 0.9925 - val_loss: 3.9121 - val_accuracy: 0.4286\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0773 - accuracy: 0.9768 - val_loss: 3.7788 - val_accuracy: 0.4884\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.1437 - accuracy: 0.9619 - val_loss: 3.5938 - val_accuracy: 0.4751\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0725 - accuracy: 0.9735 - val_loss: 4.8151 - val_accuracy: 0.4751\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.1580 - accuracy: 0.9602 - val_loss: 3.6502 - val_accuracy: 0.4751\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0833 - accuracy: 0.9776 - val_loss: 3.4111 - val_accuracy: 0.4551\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0286 - accuracy: 0.9942 - val_loss: 3.2152 - val_accuracy: 0.4585\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0129 - accuracy: 0.9975 - val_loss: 3.1083 - val_accuracy: 0.4585\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 3.5212 - val_accuracy: 0.4983\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.4607 - val_accuracy: 0.5017\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.5882 - val_accuracy: 0.5017\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 2.9866e-04 - accuracy: 1.0000 - val_loss: 3.6741 - val_accuracy: 0.5017\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.8590e-04 - accuracy: 1.0000 - val_loss: 3.7459 - val_accuracy: 0.5083\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 1.4711e-04 - accuracy: 1.0000 - val_loss: 3.7905 - val_accuracy: 0.5050\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 1.2613e-04 - accuracy: 1.0000 - val_loss: 3.8221 - val_accuracy: 0.5050\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 1.1229e-04 - accuracy: 1.0000 - val_loss: 3.8553 - val_accuracy: 0.5050\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 1.0102e-04 - accuracy: 1.0000 - val_loss: 3.8779 - val_accuracy: 0.5050\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 9.2355e-05 - accuracy: 1.0000 - val_loss: 3.9032 - val_accuracy: 0.5050\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 8.4886e-05 - accuracy: 1.0000 - val_loss: 3.9251 - val_accuracy: 0.5116\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 7.8637e-05 - accuracy: 1.0000 - val_loss: 3.9413 - val_accuracy: 0.5116\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 7.2956e-05 - accuracy: 1.0000 - val_loss: 3.9606 - val_accuracy: 0.5116\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 6.7975e-05 - accuracy: 1.0000 - val_loss: 3.9772 - val_accuracy: 0.5116\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 6.3580e-05 - accuracy: 1.0000 - val_loss: 3.9930 - val_accuracy: 0.5116\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 5.9768e-05 - accuracy: 1.0000 - val_loss: 4.0077 - val_accuracy: 0.5116\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 5.6252e-05 - accuracy: 1.0000 - val_loss: 4.0221 - val_accuracy: 0.5116\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 5.3151e-05 - accuracy: 1.0000 - val_loss: 4.0384 - val_accuracy: 0.5116\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 5.0273e-05 - accuracy: 1.0000 - val_loss: 4.0504 - val_accuracy: 0.5116\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 4.7644e-05 - accuracy: 1.0000 - val_loss: 4.0633 - val_accuracy: 0.5116\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 4.5189e-05 - accuracy: 1.0000 - val_loss: 4.0752 - val_accuracy: 0.5150\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 4.3011e-05 - accuracy: 1.0000 - val_loss: 4.0877 - val_accuracy: 0.5150\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 4.0939e-05 - accuracy: 1.0000 - val_loss: 4.0978 - val_accuracy: 0.5150\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 3.9109e-05 - accuracy: 1.0000 - val_loss: 4.1101 - val_accuracy: 0.5150\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 3.7300e-05 - accuracy: 1.0000 - val_loss: 4.1197 - val_accuracy: 0.5150\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 3.5650e-05 - accuracy: 1.0000 - val_loss: 4.1316 - val_accuracy: 0.5183\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 3.4150e-05 - accuracy: 1.0000 - val_loss: 4.1409 - val_accuracy: 0.5183\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 3.2723e-05 - accuracy: 1.0000 - val_loss: 4.1512 - val_accuracy: 0.5216\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 3.1380e-05 - accuracy: 1.0000 - val_loss: 4.1613 - val_accuracy: 0.5216\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 3.0131e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.5216\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 2.8975e-05 - accuracy: 1.0000 - val_loss: 4.1789 - val_accuracy: 0.5216\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 2.7879e-05 - accuracy: 1.0000 - val_loss: 4.1897 - val_accuracy: 0.5183\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 2.6773e-05 - accuracy: 1.0000 - val_loss: 4.1988 - val_accuracy: 0.5183\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 2.5772e-05 - accuracy: 1.0000 - val_loss: 4.2071 - val_accuracy: 0.5183\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 2.4787e-05 - accuracy: 1.0000 - val_loss: 4.2169 - val_accuracy: 0.5183\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 2.3839e-05 - accuracy: 1.0000 - val_loss: 4.2264 - val_accuracy: 0.5183\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 2.2975e-05 - accuracy: 1.0000 - val_loss: 4.2348 - val_accuracy: 0.5183\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 2.2157e-05 - accuracy: 1.0000 - val_loss: 4.2439 - val_accuracy: 0.5183\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 2.1373e-05 - accuracy: 1.0000 - val_loss: 4.2518 - val_accuracy: 0.5183\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 2.0647e-05 - accuracy: 1.0000 - val_loss: 4.2602 - val_accuracy: 0.5183\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 1.9941e-05 - accuracy: 1.0000 - val_loss: 4.2690 - val_accuracy: 0.5183\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 1.9277e-05 - accuracy: 1.0000 - val_loss: 4.2772 - val_accuracy: 0.5183\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.8626e-05 - accuracy: 1.0000 - val_loss: 4.2854 - val_accuracy: 0.5150\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.8038e-05 - accuracy: 1.0000 - val_loss: 4.2929 - val_accuracy: 0.5150\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.7460e-05 - accuracy: 1.0000 - val_loss: 4.3014 - val_accuracy: 0.5150\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.6904e-05 - accuracy: 1.0000 - val_loss: 4.3089 - val_accuracy: 0.5150\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.6372e-05 - accuracy: 1.0000 - val_loss: 4.3162 - val_accuracy: 0.5150\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.5869e-05 - accuracy: 1.0000 - val_loss: 4.3243 - val_accuracy: 0.5150\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.5377e-05 - accuracy: 1.0000 - val_loss: 4.3324 - val_accuracy: 0.5150\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.4918e-05 - accuracy: 1.0000 - val_loss: 4.3393 - val_accuracy: 0.5150\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.4465e-05 - accuracy: 1.0000 - val_loss: 4.3471 - val_accuracy: 0.5150\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 4s 119ms/step - loss: 1.4058e-05 - accuracy: 1.0000 - val_loss: 4.3545 - val_accuracy: 0.5116\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.3630e-05 - accuracy: 1.0000 - val_loss: 4.3619 - val_accuracy: 0.5083\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.3242e-05 - accuracy: 1.0000 - val_loss: 4.3686 - val_accuracy: 0.5083\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.2865e-05 - accuracy: 1.0000 - val_loss: 4.3761 - val_accuracy: 0.5083\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 1.2497e-05 - accuracy: 1.0000 - val_loss: 4.3840 - val_accuracy: 0.5083\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.2144e-05 - accuracy: 1.0000 - val_loss: 4.3909 - val_accuracy: 0.5116\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.1804e-05 - accuracy: 1.0000 - val_loss: 4.3976 - val_accuracy: 0.5116\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.1464e-05 - accuracy: 1.0000 - val_loss: 4.4052 - val_accuracy: 0.5116\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.1150e-05 - accuracy: 1.0000 - val_loss: 4.4123 - val_accuracy: 0.5116\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.0836e-05 - accuracy: 1.0000 - val_loss: 4.4195 - val_accuracy: 0.5150\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.0550e-05 - accuracy: 1.0000 - val_loss: 4.4273 - val_accuracy: 0.5150\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 4s 119ms/step - loss: 1.0254e-05 - accuracy: 1.0000 - val_loss: 4.4337 - val_accuracy: 0.5150\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 9.9778e-06 - accuracy: 1.0000 - val_loss: 4.4411 - val_accuracy: 0.5183\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 9.7133e-06 - accuracy: 1.0000 - val_loss: 4.4480 - val_accuracy: 0.5183\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 9.4471e-06 - accuracy: 1.0000 - val_loss: 4.4548 - val_accuracy: 0.5183\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 9.1904e-06 - accuracy: 1.0000 - val_loss: 4.4616 - val_accuracy: 0.5183\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 8.9505e-06 - accuracy: 1.0000 - val_loss: 4.4681 - val_accuracy: 0.5183\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 8.7191e-06 - accuracy: 1.0000 - val_loss: 4.4753 - val_accuracy: 0.5150\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 8.4859e-06 - accuracy: 1.0000 - val_loss: 4.4820 - val_accuracy: 0.5183\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 8.2704e-06 - accuracy: 1.0000 - val_loss: 4.4887 - val_accuracy: 0.5183\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 8.0595e-06 - accuracy: 1.0000 - val_loss: 4.4948 - val_accuracy: 0.5183\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 7.8512e-06 - accuracy: 1.0000 - val_loss: 4.5015 - val_accuracy: 0.5216\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 7.6487e-06 - accuracy: 1.0000 - val_loss: 4.5081 - val_accuracy: 0.5216\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 7.4522e-06 - accuracy: 1.0000 - val_loss: 4.5148 - val_accuracy: 0.5216\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 4s 119ms/step - loss: 7.2635e-06 - accuracy: 1.0000 - val_loss: 4.5208 - val_accuracy: 0.5216\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 4s 119ms/step - loss: 7.0776e-06 - accuracy: 1.0000 - val_loss: 4.5274 - val_accuracy: 0.5216\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 6.9018e-06 - accuracy: 1.0000 - val_loss: 4.5348 - val_accuracy: 0.5216\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 6.7230e-06 - accuracy: 1.0000 - val_loss: 4.5409 - val_accuracy: 0.5216\n",
      "10/10 [==============================] - 0s 31ms/step\n",
      "Fold 4\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 5s 118ms/step - loss: 23.6473 - accuracy: 0.1609 - val_loss: 2.2458 - val_accuracy: 0.2326\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 1.9691 - accuracy: 0.3474 - val_loss: 2.1198 - val_accuracy: 0.3488\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 5s 118ms/step - loss: 1.4155 - accuracy: 0.5498 - val_loss: 1.9953 - val_accuracy: 0.4153\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.8865 - accuracy: 0.7454 - val_loss: 2.0226 - val_accuracy: 0.4352\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.5451 - accuracy: 0.8425 - val_loss: 2.1977 - val_accuracy: 0.4485\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.3260 - accuracy: 0.9328 - val_loss: 2.2480 - val_accuracy: 0.4983\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 4s 119ms/step - loss: 0.1535 - accuracy: 0.9610 - val_loss: 2.5278 - val_accuracy: 0.4817\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.1805 - accuracy: 0.9577 - val_loss: 2.7802 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0956 - accuracy: 0.9801 - val_loss: 2.9966 - val_accuracy: 0.4950\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 5s 117ms/step - loss: 0.0652 - accuracy: 0.9842 - val_loss: 3.0503 - val_accuracy: 0.4983\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.0245 - accuracy: 0.9967 - val_loss: 3.1163 - val_accuracy: 0.5249\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 3.3269 - val_accuracy: 0.5249\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 0.0217 - accuracy: 0.9959 - val_loss: 3.7984 - val_accuracy: 0.5316\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0363 - accuracy: 0.9942 - val_loss: 3.3334 - val_accuracy: 0.5249\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 3.5478 - val_accuracy: 0.5249\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 3.3253 - val_accuracy: 0.5183\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 3.5103 - val_accuracy: 0.5349\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.6043 - val_accuracy: 0.5515\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 6.8716e-04 - accuracy: 1.0000 - val_loss: 3.7023 - val_accuracy: 0.5548\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 4.7562e-04 - accuracy: 1.0000 - val_loss: 3.7708 - val_accuracy: 0.5581\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 3.6580e-04 - accuracy: 1.0000 - val_loss: 3.8000 - val_accuracy: 0.5581\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 3.0046e-04 - accuracy: 1.0000 - val_loss: 3.8408 - val_accuracy: 0.5648\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 2.5439e-04 - accuracy: 1.0000 - val_loss: 3.8761 - val_accuracy: 0.5648\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 5s 118ms/step - loss: 2.2014e-04 - accuracy: 1.0000 - val_loss: 3.9088 - val_accuracy: 0.5615\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.9237e-04 - accuracy: 1.0000 - val_loss: 3.9369 - val_accuracy: 0.5648\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.7008e-04 - accuracy: 1.0000 - val_loss: 3.9633 - val_accuracy: 0.5648\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.5183e-04 - accuracy: 1.0000 - val_loss: 3.9859 - val_accuracy: 0.5648\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.3669e-04 - accuracy: 1.0000 - val_loss: 4.0043 - val_accuracy: 0.5648\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 1.2397e-04 - accuracy: 1.0000 - val_loss: 4.0327 - val_accuracy: 0.5615\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 1.1296e-04 - accuracy: 1.0000 - val_loss: 4.0520 - val_accuracy: 0.5615\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 1.0383e-04 - accuracy: 1.0000 - val_loss: 4.0693 - val_accuracy: 0.5615\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 9.5280e-05 - accuracy: 1.0000 - val_loss: 4.0913 - val_accuracy: 0.5615\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 8.8306e-05 - accuracy: 1.0000 - val_loss: 4.1101 - val_accuracy: 0.5615\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 8.1720e-05 - accuracy: 1.0000 - val_loss: 4.1276 - val_accuracy: 0.5615\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 7.6361e-05 - accuracy: 1.0000 - val_loss: 4.1450 - val_accuracy: 0.5615\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 7.0869e-05 - accuracy: 1.0000 - val_loss: 4.1775 - val_accuracy: 0.5615\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 6.6292e-05 - accuracy: 1.0000 - val_loss: 4.1905 - val_accuracy: 0.5615\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 6.2026e-05 - accuracy: 1.0000 - val_loss: 4.2077 - val_accuracy: 0.5615\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 5.8244e-05 - accuracy: 1.0000 - val_loss: 4.2295 - val_accuracy: 0.5615\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 5.4799e-05 - accuracy: 1.0000 - val_loss: 4.2431 - val_accuracy: 0.5615\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 5.1744e-05 - accuracy: 1.0000 - val_loss: 4.2623 - val_accuracy: 0.5615\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 4.8900e-05 - accuracy: 1.0000 - val_loss: 4.2780 - val_accuracy: 0.5615\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 4.6260e-05 - accuracy: 1.0000 - val_loss: 4.2939 - val_accuracy: 0.5615\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 4.3930e-05 - accuracy: 1.0000 - val_loss: 4.3099 - val_accuracy: 0.5615\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 4.1683e-05 - accuracy: 1.0000 - val_loss: 4.3261 - val_accuracy: 0.5615\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 3.9629e-05 - accuracy: 1.0000 - val_loss: 4.3387 - val_accuracy: 0.5581\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 3.7741e-05 - accuracy: 1.0000 - val_loss: 4.3535 - val_accuracy: 0.5581\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 3.5997e-05 - accuracy: 1.0000 - val_loss: 4.3675 - val_accuracy: 0.5548\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 3.4342e-05 - accuracy: 1.0000 - val_loss: 4.3815 - val_accuracy: 0.5548\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 3.2851e-05 - accuracy: 1.0000 - val_loss: 4.3934 - val_accuracy: 0.5548\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 3.1347e-05 - accuracy: 1.0000 - val_loss: 4.4075 - val_accuracy: 0.5482\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 2.9948e-05 - accuracy: 1.0000 - val_loss: 4.4198 - val_accuracy: 0.5515\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 2.8603e-05 - accuracy: 1.0000 - val_loss: 4.4347 - val_accuracy: 0.5515\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 2.7315e-05 - accuracy: 1.0000 - val_loss: 4.4450 - val_accuracy: 0.5515\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 2.6175e-05 - accuracy: 1.0000 - val_loss: 4.4588 - val_accuracy: 0.5482\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 2.5062e-05 - accuracy: 1.0000 - val_loss: 4.4704 - val_accuracy: 0.5482\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 2.4017e-05 - accuracy: 1.0000 - val_loss: 4.4774 - val_accuracy: 0.5482\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 2.3058e-05 - accuracy: 1.0000 - val_loss: 4.4913 - val_accuracy: 0.5482\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 2.2151e-05 - accuracy: 1.0000 - val_loss: 4.4993 - val_accuracy: 0.5482\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 2.1290e-05 - accuracy: 1.0000 - val_loss: 4.5111 - val_accuracy: 0.5482\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 2.0441e-05 - accuracy: 1.0000 - val_loss: 4.5220 - val_accuracy: 0.5482\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 1.9655e-05 - accuracy: 1.0000 - val_loss: 4.5295 - val_accuracy: 0.5548\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.8915e-05 - accuracy: 1.0000 - val_loss: 4.5405 - val_accuracy: 0.5548\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.8205e-05 - accuracy: 1.0000 - val_loss: 4.5504 - val_accuracy: 0.5548\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.7544e-05 - accuracy: 1.0000 - val_loss: 4.5614 - val_accuracy: 0.5548\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.6897e-05 - accuracy: 1.0000 - val_loss: 4.5702 - val_accuracy: 0.5548\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.6279e-05 - accuracy: 1.0000 - val_loss: 4.5799 - val_accuracy: 0.5548\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 1.5707e-05 - accuracy: 1.0000 - val_loss: 4.5903 - val_accuracy: 0.5515\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.5161e-05 - accuracy: 1.0000 - val_loss: 4.5984 - val_accuracy: 0.5515\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.4628e-05 - accuracy: 1.0000 - val_loss: 4.6074 - val_accuracy: 0.5515\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.4126e-05 - accuracy: 1.0000 - val_loss: 4.6174 - val_accuracy: 0.5515\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 1.3656e-05 - accuracy: 1.0000 - val_loss: 4.6263 - val_accuracy: 0.5515\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.3195e-05 - accuracy: 1.0000 - val_loss: 4.6367 - val_accuracy: 0.5515\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.2760e-05 - accuracy: 1.0000 - val_loss: 4.6469 - val_accuracy: 0.5515\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.2349e-05 - accuracy: 1.0000 - val_loss: 4.6561 - val_accuracy: 0.5515\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 1.1956e-05 - accuracy: 1.0000 - val_loss: 4.6634 - val_accuracy: 0.5515\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 1.1563e-05 - accuracy: 1.0000 - val_loss: 4.6730 - val_accuracy: 0.5515\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 5s 143ms/step - loss: 1.1188e-05 - accuracy: 1.0000 - val_loss: 4.6812 - val_accuracy: 0.5515\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 1.0842e-05 - accuracy: 1.0000 - val_loss: 4.6902 - val_accuracy: 0.5449\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.0500e-05 - accuracy: 1.0000 - val_loss: 4.7013 - val_accuracy: 0.5449\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 1.0164e-05 - accuracy: 1.0000 - val_loss: 4.7106 - val_accuracy: 0.5449\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 9.8538e-06 - accuracy: 1.0000 - val_loss: 4.7192 - val_accuracy: 0.5415\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 9.5436e-06 - accuracy: 1.0000 - val_loss: 4.7277 - val_accuracy: 0.5415\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 9.2587e-06 - accuracy: 1.0000 - val_loss: 4.7362 - val_accuracy: 0.5415\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 8.9792e-06 - accuracy: 1.0000 - val_loss: 4.7460 - val_accuracy: 0.5415\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 8.7161e-06 - accuracy: 1.0000 - val_loss: 4.7558 - val_accuracy: 0.5415\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 8.4537e-06 - accuracy: 1.0000 - val_loss: 4.7642 - val_accuracy: 0.5415\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 8.2047e-06 - accuracy: 1.0000 - val_loss: 4.7720 - val_accuracy: 0.5415\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 7.9594e-06 - accuracy: 1.0000 - val_loss: 4.7821 - val_accuracy: 0.5415\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 7.7347e-06 - accuracy: 1.0000 - val_loss: 4.7923 - val_accuracy: 0.5415\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 7.5042e-06 - accuracy: 1.0000 - val_loss: 4.7998 - val_accuracy: 0.5415\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 7.2901e-06 - accuracy: 1.0000 - val_loss: 4.8075 - val_accuracy: 0.5415\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 7.0818e-06 - accuracy: 1.0000 - val_loss: 4.8157 - val_accuracy: 0.5415\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 6.8801e-06 - accuracy: 1.0000 - val_loss: 4.8257 - val_accuracy: 0.5415\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 6.6913e-06 - accuracy: 1.0000 - val_loss: 4.8349 - val_accuracy: 0.5415\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 6.4913e-06 - accuracy: 1.0000 - val_loss: 4.8433 - val_accuracy: 0.5415\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 6.3170e-06 - accuracy: 1.0000 - val_loss: 4.8522 - val_accuracy: 0.5415\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 6.1381e-06 - accuracy: 1.0000 - val_loss: 4.8602 - val_accuracy: 0.5415\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 5.9672e-06 - accuracy: 1.0000 - val_loss: 4.8699 - val_accuracy: 0.5415\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 5.8099e-06 - accuracy: 1.0000 - val_loss: 4.8784 - val_accuracy: 0.5449\n",
      "10/10 [==============================] - 0s 35ms/step\n",
      "Fold 5\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 6s 134ms/step - loss: 13.4281 - accuracy: 0.1567 - val_loss: 2.1679 - val_accuracy: 0.1495\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 1.9755 - accuracy: 0.3085 - val_loss: 2.1217 - val_accuracy: 0.2359\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 1.6257 - accuracy: 0.4801 - val_loss: 2.0981 - val_accuracy: 0.3455\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.9480 - accuracy: 0.7065 - val_loss: 2.0463 - val_accuracy: 0.3821\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.3309 - accuracy: 0.9080 - val_loss: 2.3535 - val_accuracy: 0.3987\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.1030 - accuracy: 0.9743 - val_loss: 2.5076 - val_accuracy: 0.4385\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0291 - accuracy: 0.9967 - val_loss: 2.6689 - val_accuracy: 0.4718\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.7022 - val_accuracy: 0.4718\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9331 - val_accuracy: 0.4718\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 6s 158ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9951 - val_accuracy: 0.4784\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 9.3557e-04 - accuracy: 1.0000 - val_loss: 3.0544 - val_accuracy: 0.4850\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 7.3091e-04 - accuracy: 1.0000 - val_loss: 3.0986 - val_accuracy: 0.4817\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 5.9843e-04 - accuracy: 1.0000 - val_loss: 3.1377 - val_accuracy: 0.4817\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 5.0336e-04 - accuracy: 1.0000 - val_loss: 3.1724 - val_accuracy: 0.4817\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 4.2973e-04 - accuracy: 1.0000 - val_loss: 3.2147 - val_accuracy: 0.4817\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 3.7024e-04 - accuracy: 1.0000 - val_loss: 3.2375 - val_accuracy: 0.4817\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 3.2413e-04 - accuracy: 1.0000 - val_loss: 3.2646 - val_accuracy: 0.4850\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 2.8499e-04 - accuracy: 1.0000 - val_loss: 3.2863 - val_accuracy: 0.4850\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 2.5399e-04 - accuracy: 1.0000 - val_loss: 3.3055 - val_accuracy: 0.4884\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 2.2752e-04 - accuracy: 1.0000 - val_loss: 3.3259 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 2.0609e-04 - accuracy: 1.0000 - val_loss: 3.3441 - val_accuracy: 0.5017\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 1.8629e-04 - accuracy: 1.0000 - val_loss: 3.3666 - val_accuracy: 0.4983\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 1.6914e-04 - accuracy: 1.0000 - val_loss: 3.3776 - val_accuracy: 0.5017\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.5502e-04 - accuracy: 1.0000 - val_loss: 3.3974 - val_accuracy: 0.5050\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 1.4213e-04 - accuracy: 1.0000 - val_loss: 3.4111 - val_accuracy: 0.5083\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.3113e-04 - accuracy: 1.0000 - val_loss: 3.4285 - val_accuracy: 0.5083\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 1.2104e-04 - accuracy: 1.0000 - val_loss: 3.4422 - val_accuracy: 0.5083\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 1.1227e-04 - accuracy: 1.0000 - val_loss: 3.4596 - val_accuracy: 0.5050\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 1.0428e-04 - accuracy: 1.0000 - val_loss: 3.4748 - val_accuracy: 0.5050\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 9.7291e-05 - accuracy: 1.0000 - val_loss: 3.4912 - val_accuracy: 0.5050\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 9.0818e-05 - accuracy: 1.0000 - val_loss: 3.5046 - val_accuracy: 0.5050\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 8.4800e-05 - accuracy: 1.0000 - val_loss: 3.5217 - val_accuracy: 0.5050\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 7.9328e-05 - accuracy: 1.0000 - val_loss: 3.5340 - val_accuracy: 0.5050\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 7.4463e-05 - accuracy: 1.0000 - val_loss: 3.5482 - val_accuracy: 0.5017\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 6.9947e-05 - accuracy: 1.0000 - val_loss: 3.5606 - val_accuracy: 0.5050\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 6.5796e-05 - accuracy: 1.0000 - val_loss: 3.5721 - val_accuracy: 0.5017\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 6.2140e-05 - accuracy: 1.0000 - val_loss: 3.5830 - val_accuracy: 0.5017\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 5.8607e-05 - accuracy: 1.0000 - val_loss: 3.5984 - val_accuracy: 0.5050\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 5.5446e-05 - accuracy: 1.0000 - val_loss: 3.6054 - val_accuracy: 0.5017\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 5.2562e-05 - accuracy: 1.0000 - val_loss: 3.6143 - val_accuracy: 0.5017\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 4.9868e-05 - accuracy: 1.0000 - val_loss: 3.6280 - val_accuracy: 0.5017\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 4.7389e-05 - accuracy: 1.0000 - val_loss: 3.6351 - val_accuracy: 0.5050\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 4.4999e-05 - accuracy: 1.0000 - val_loss: 3.6469 - val_accuracy: 0.5050\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 4.2800e-05 - accuracy: 1.0000 - val_loss: 3.6553 - val_accuracy: 0.5017\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 4.0756e-05 - accuracy: 1.0000 - val_loss: 3.6654 - val_accuracy: 0.5083\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 3.8812e-05 - accuracy: 1.0000 - val_loss: 3.6722 - val_accuracy: 0.5083\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 3.7068e-05 - accuracy: 1.0000 - val_loss: 3.6809 - val_accuracy: 0.5116\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 3.5349e-05 - accuracy: 1.0000 - val_loss: 3.6890 - val_accuracy: 0.5083\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 3.3752e-05 - accuracy: 1.0000 - val_loss: 3.6966 - val_accuracy: 0.5116\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 3.2218e-05 - accuracy: 1.0000 - val_loss: 3.7075 - val_accuracy: 0.5150\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 3.0826e-05 - accuracy: 1.0000 - val_loss: 3.7150 - val_accuracy: 0.5116\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.9462e-05 - accuracy: 1.0000 - val_loss: 3.7246 - val_accuracy: 0.5116\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 2.8208e-05 - accuracy: 1.0000 - val_loss: 3.7301 - val_accuracy: 0.5116\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.6983e-05 - accuracy: 1.0000 - val_loss: 3.7400 - val_accuracy: 0.5150\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.5860e-05 - accuracy: 1.0000 - val_loss: 3.7477 - val_accuracy: 0.5150\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.4781e-05 - accuracy: 1.0000 - val_loss: 3.7560 - val_accuracy: 0.5150\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 2.3779e-05 - accuracy: 1.0000 - val_loss: 3.7640 - val_accuracy: 0.5150\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 2.2815e-05 - accuracy: 1.0000 - val_loss: 3.7719 - val_accuracy: 0.5150\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 2.1905e-05 - accuracy: 1.0000 - val_loss: 3.7790 - val_accuracy: 0.5150\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 2.1045e-05 - accuracy: 1.0000 - val_loss: 3.7844 - val_accuracy: 0.5150\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 2.0245e-05 - accuracy: 1.0000 - val_loss: 3.7955 - val_accuracy: 0.5150\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 1.9438e-05 - accuracy: 1.0000 - val_loss: 3.8018 - val_accuracy: 0.5150\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 1.8707e-05 - accuracy: 1.0000 - val_loss: 3.8112 - val_accuracy: 0.5150\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 1.8010e-05 - accuracy: 1.0000 - val_loss: 3.8187 - val_accuracy: 0.5150\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 1.7344e-05 - accuracy: 1.0000 - val_loss: 3.8269 - val_accuracy: 0.5150\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 1.6724e-05 - accuracy: 1.0000 - val_loss: 3.8327 - val_accuracy: 0.5183\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 1.6158e-05 - accuracy: 1.0000 - val_loss: 3.8402 - val_accuracy: 0.5183\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 1.5553e-05 - accuracy: 1.0000 - val_loss: 3.8457 - val_accuracy: 0.5183\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 1.5000e-05 - accuracy: 1.0000 - val_loss: 3.8512 - val_accuracy: 0.5183\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 1.4493e-05 - accuracy: 1.0000 - val_loss: 3.8598 - val_accuracy: 0.5183\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 1.3993e-05 - accuracy: 1.0000 - val_loss: 3.8654 - val_accuracy: 0.5183\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 1.3527e-05 - accuracy: 1.0000 - val_loss: 3.8712 - val_accuracy: 0.5183\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 1.3071e-05 - accuracy: 1.0000 - val_loss: 3.8780 - val_accuracy: 0.5183\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 1.2631e-05 - accuracy: 1.0000 - val_loss: 3.8854 - val_accuracy: 0.5183\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 1.2226e-05 - accuracy: 1.0000 - val_loss: 3.8927 - val_accuracy: 0.5216\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 1.1825e-05 - accuracy: 1.0000 - val_loss: 3.8964 - val_accuracy: 0.5216\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 1.1436e-05 - accuracy: 1.0000 - val_loss: 3.9051 - val_accuracy: 0.5216\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 1.1056e-05 - accuracy: 1.0000 - val_loss: 3.9082 - val_accuracy: 0.5216\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 1.0692e-05 - accuracy: 1.0000 - val_loss: 3.9191 - val_accuracy: 0.5216\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 1.0339e-05 - accuracy: 1.0000 - val_loss: 3.9246 - val_accuracy: 0.5282\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 9.9444e-06 - accuracy: 1.0000 - val_loss: 3.9322 - val_accuracy: 0.5282\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 9.6220e-06 - accuracy: 1.0000 - val_loss: 3.9401 - val_accuracy: 0.5316\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 9.3131e-06 - accuracy: 1.0000 - val_loss: 3.9454 - val_accuracy: 0.5282\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 9.0163e-06 - accuracy: 1.0000 - val_loss: 3.9517 - val_accuracy: 0.5316\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 8.7305e-06 - accuracy: 1.0000 - val_loss: 3.9580 - val_accuracy: 0.5282\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 8.4434e-06 - accuracy: 1.0000 - val_loss: 3.9648 - val_accuracy: 0.5282\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 8.1892e-06 - accuracy: 1.0000 - val_loss: 3.9683 - val_accuracy: 0.5282\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 7s 191ms/step - loss: 7.9361e-06 - accuracy: 1.0000 - val_loss: 3.9745 - val_accuracy: 0.5316\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 7s 196ms/step - loss: 7.6971e-06 - accuracy: 1.0000 - val_loss: 3.9824 - val_accuracy: 0.5316\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 8s 201ms/step - loss: 7.4630e-06 - accuracy: 1.0000 - val_loss: 3.9867 - val_accuracy: 0.5316\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 7s 194ms/step - loss: 7.2418e-06 - accuracy: 1.0000 - val_loss: 3.9928 - val_accuracy: 0.5316\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 8s 198ms/step - loss: 7.0328e-06 - accuracy: 1.0000 - val_loss: 3.9965 - val_accuracy: 0.5349\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 8s 202ms/step - loss: 6.8225e-06 - accuracy: 1.0000 - val_loss: 4.0037 - val_accuracy: 0.5316\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 7s 197ms/step - loss: 6.6316e-06 - accuracy: 1.0000 - val_loss: 4.0092 - val_accuracy: 0.5349\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 8s 200ms/step - loss: 6.4362e-06 - accuracy: 1.0000 - val_loss: 4.0145 - val_accuracy: 0.5349\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 7s 197ms/step - loss: 6.2559e-06 - accuracy: 1.0000 - val_loss: 4.0191 - val_accuracy: 0.5349\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 7s 197ms/step - loss: 6.0791e-06 - accuracy: 1.0000 - val_loss: 4.0241 - val_accuracy: 0.5349\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 8s 201ms/step - loss: 5.9092e-06 - accuracy: 1.0000 - val_loss: 4.0307 - val_accuracy: 0.5349\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 8s 198ms/step - loss: 5.7442e-06 - accuracy: 1.0000 - val_loss: 4.0367 - val_accuracy: 0.5349\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 8s 198ms/step - loss: 5.5866e-06 - accuracy: 1.0000 - val_loss: 4.0401 - val_accuracy: 0.5349\n",
      "10/10 [==============================] - 1s 86ms/step\n",
      "Cross-validation results:\n",
      "Mean validation accuracy: 0.5342 (+/- 0.0374)\n",
      "fit time 534.6247158050537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the number of folds for cross-validation and other hyperparameters\n",
    "n_folds = 5  # Number of folds for cross-validation\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_deep = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "val_accuracy_per_fold = []\n",
    "\n",
    "# Perform cross-validation using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(images, labels_deep)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train_fold = images[train_index]\n",
    "    y_train_fold = labels_deep[train_index]\n",
    "    X_val_fold = images[val_index]\n",
    "    y_val_fold = labels_deep[val_index]\n",
    "\n",
    "    # Encode the labels\n",
    "    #label_encoder = LabelEncoder()\n",
    "    #y_train_fold = label_encoder.fit_transform(y_train_fold)\n",
    "    #y_val_fold = label_encoder.fit_transform(y_val_fold)\n",
    "\n",
    "    # Define the input shape and number of classes\n",
    "    input_shape = X_train.shape[1:]\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    # Create the LeNet model\n",
    "    model = create_LeNet_model(input_shape, num_classes)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=batch_size, epochs=epochs, validation_data=(X_val_fold, y_val_fold))\n",
    "\n",
    "    fit_time = time.time() - start\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "    y_val_true_labels = y_val_fold\n",
    "    #np.argmax(np.reshape(y_val_fold, (-1, 1)), axis=1)\n",
    "    val_accuracy = accuracy_score(y_val_true_labels, y_val_pred_labels)\n",
    "\n",
    "    val_accuracy_per_fold.append(val_accuracy)\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the evaluation metrics across folds\n",
    "print(\"Cross-validation results:\")\n",
    "print(f\"Mean validation accuracy: {np.mean(val_accuracy_per_fold):.4f} (+/- {np.std(val_accuracy_per_fold):.4f})\")\n",
    "print(\"fit time\", fit_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data augmentation \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 12s 281ms/step - loss: 5.2275 - accuracy: 0.1519 - val_loss: 2.3385 - val_accuracy: 0.1987\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 8s 211ms/step - loss: 2.1386 - accuracy: 0.2390 - val_loss: 2.1865 - val_accuracy: 0.2219\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 2.0814 - accuracy: 0.2249 - val_loss: 2.1553 - val_accuracy: 0.2219\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 12s 305ms/step - loss: 2.0554 - accuracy: 0.2465 - val_loss: 2.1202 - val_accuracy: 0.2517\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 2.0443 - accuracy: 0.2373 - val_loss: 2.1053 - val_accuracy: 0.2649\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 12s 301ms/step - loss: 2.0154 - accuracy: 0.2531 - val_loss: 2.0643 - val_accuracy: 0.2616\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 2.0061 - accuracy: 0.2589 - val_loss: 2.0478 - val_accuracy: 0.2483\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 12s 318ms/step - loss: 2.0185 - accuracy: 0.2423 - val_loss: 1.9812 - val_accuracy: 0.2550\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.9646 - accuracy: 0.2747 - val_loss: 1.9825 - val_accuracy: 0.2517\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.9373 - accuracy: 0.2772 - val_loss: 1.9085 - val_accuracy: 0.3113\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 15s 380ms/step - loss: 1.9220 - accuracy: 0.2913 - val_loss: 1.9112 - val_accuracy: 0.3179\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 17s 454ms/step - loss: 1.9147 - accuracy: 0.3104 - val_loss: 1.8741 - val_accuracy: 0.3444\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 1.8737 - accuracy: 0.3120 - val_loss: 1.8985 - val_accuracy: 0.3609\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 14s 369ms/step - loss: 1.9031 - accuracy: 0.3286 - val_loss: 1.7831 - val_accuracy: 0.3576\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.8388 - accuracy: 0.3585 - val_loss: 1.7952 - val_accuracy: 0.3775\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.8375 - accuracy: 0.3436 - val_loss: 1.7714 - val_accuracy: 0.3874\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 14s 367ms/step - loss: 1.8297 - accuracy: 0.3477 - val_loss: 1.7650 - val_accuracy: 0.3940\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 15s 380ms/step - loss: 1.8047 - accuracy: 0.3419 - val_loss: 1.6978 - val_accuracy: 0.4272\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 14s 376ms/step - loss: 1.7856 - accuracy: 0.3560 - val_loss: 1.8116 - val_accuracy: 0.4073\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 14s 354ms/step - loss: 1.7580 - accuracy: 0.3685 - val_loss: 1.7003 - val_accuracy: 0.4139\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 15s 378ms/step - loss: 1.7688 - accuracy: 0.3502 - val_loss: 1.6806 - val_accuracy: 0.4139\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 14s 370ms/step - loss: 1.7468 - accuracy: 0.3867 - val_loss: 1.6592 - val_accuracy: 0.4205\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 15s 379ms/step - loss: 1.7461 - accuracy: 0.3693 - val_loss: 1.6423 - val_accuracy: 0.4437\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 1.7022 - accuracy: 0.3967 - val_loss: 1.7008 - val_accuracy: 0.4371\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 14s 364ms/step - loss: 1.6796 - accuracy: 0.3909 - val_loss: 1.6059 - val_accuracy: 0.4404\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 14s 381ms/step - loss: 1.7222 - accuracy: 0.3826 - val_loss: 1.6096 - val_accuracy: 0.4305\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 14s 367ms/step - loss: 1.6657 - accuracy: 0.3959 - val_loss: 1.6216 - val_accuracy: 0.4603\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 13s 345ms/step - loss: 1.6866 - accuracy: 0.3992 - val_loss: 1.5590 - val_accuracy: 0.4570\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.6470 - accuracy: 0.4158 - val_loss: 1.5847 - val_accuracy: 0.4702\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 13s 351ms/step - loss: 1.5942 - accuracy: 0.4191 - val_loss: 1.4932 - val_accuracy: 0.4934\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 14s 366ms/step - loss: 1.6237 - accuracy: 0.4216 - val_loss: 1.4608 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 1.6452 - accuracy: 0.4149 - val_loss: 1.5759 - val_accuracy: 0.4768\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 1.6001 - accuracy: 0.4199 - val_loss: 1.4512 - val_accuracy: 0.4967\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.5687 - accuracy: 0.4332 - val_loss: 1.5887 - val_accuracy: 0.4702\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.5135 - accuracy: 0.4606 - val_loss: 1.4436 - val_accuracy: 0.4834\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 13s 331ms/step - loss: 1.5364 - accuracy: 0.4523 - val_loss: 1.4933 - val_accuracy: 0.4702\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.5588 - accuracy: 0.4440 - val_loss: 1.5016 - val_accuracy: 0.4636\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 14s 358ms/step - loss: 1.5727 - accuracy: 0.4398 - val_loss: 1.4601 - val_accuracy: 0.4636\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 14s 372ms/step - loss: 1.5832 - accuracy: 0.4382 - val_loss: 1.4516 - val_accuracy: 0.4702\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 1.5343 - accuracy: 0.4564 - val_loss: 1.4704 - val_accuracy: 0.4967\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.4939 - accuracy: 0.4739 - val_loss: 1.4792 - val_accuracy: 0.4868\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 1.4748 - accuracy: 0.4730 - val_loss: 1.4696 - val_accuracy: 0.4768\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.5184 - accuracy: 0.4631 - val_loss: 1.4980 - val_accuracy: 0.4603\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.4666 - accuracy: 0.4780 - val_loss: 1.4028 - val_accuracy: 0.4834\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 13s 352ms/step - loss: 1.4919 - accuracy: 0.4622 - val_loss: 1.3550 - val_accuracy: 0.5199\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.4584 - accuracy: 0.4730 - val_loss: 1.4131 - val_accuracy: 0.5298\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.4355 - accuracy: 0.4954 - val_loss: 1.3862 - val_accuracy: 0.5232\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4251 - accuracy: 0.4921 - val_loss: 1.3226 - val_accuracy: 0.5232\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.4407 - accuracy: 0.4863 - val_loss: 1.3624 - val_accuracy: 0.5232\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.4348 - accuracy: 0.4954 - val_loss: 1.3302 - val_accuracy: 0.5166\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.4555 - accuracy: 0.4780 - val_loss: 1.3699 - val_accuracy: 0.5199\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 15s 400ms/step - loss: 1.4231 - accuracy: 0.4855 - val_loss: 1.3659 - val_accuracy: 0.5066\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 1.4062 - accuracy: 0.5037 - val_loss: 1.3728 - val_accuracy: 0.5265\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 14s 358ms/step - loss: 1.3898 - accuracy: 0.5079 - val_loss: 1.4870 - val_accuracy: 0.4934\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.4148 - accuracy: 0.4963 - val_loss: 1.3923 - val_accuracy: 0.5232\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 1.3516 - accuracy: 0.5237 - val_loss: 1.4428 - val_accuracy: 0.5397\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 14s 354ms/step - loss: 1.4118 - accuracy: 0.5095 - val_loss: 1.3428 - val_accuracy: 0.5430\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.3539 - accuracy: 0.5295 - val_loss: 1.3267 - val_accuracy: 0.5232\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.3814 - accuracy: 0.5237 - val_loss: 1.3732 - val_accuracy: 0.5099\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 1.3751 - accuracy: 0.4921 - val_loss: 1.3447 - val_accuracy: 0.5397\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 13s 334ms/step - loss: 1.2850 - accuracy: 0.5419 - val_loss: 1.3961 - val_accuracy: 0.4934\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 1.3466 - accuracy: 0.5245 - val_loss: 1.3012 - val_accuracy: 0.5430\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.3062 - accuracy: 0.5444 - val_loss: 1.3228 - val_accuracy: 0.5629\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 13s 326ms/step - loss: 1.2847 - accuracy: 0.5461 - val_loss: 1.3666 - val_accuracy: 0.5199\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.2804 - accuracy: 0.5668 - val_loss: 1.5702 - val_accuracy: 0.4702\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.3605 - accuracy: 0.5336 - val_loss: 1.3814 - val_accuracy: 0.5397\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 14s 346ms/step - loss: 1.3360 - accuracy: 0.5402 - val_loss: 1.2802 - val_accuracy: 0.5629\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.2921 - accuracy: 0.5444 - val_loss: 1.2497 - val_accuracy: 0.5695\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.2749 - accuracy: 0.5552 - val_loss: 1.2804 - val_accuracy: 0.5530\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 13s 352ms/step - loss: 1.2654 - accuracy: 0.5369 - val_loss: 1.3500 - val_accuracy: 0.5265\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.2462 - accuracy: 0.5527 - val_loss: 1.2467 - val_accuracy: 0.5828\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 14s 354ms/step - loss: 1.3400 - accuracy: 0.5203 - val_loss: 1.3617 - val_accuracy: 0.5331\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 14s 361ms/step - loss: 1.2552 - accuracy: 0.5593 - val_loss: 1.2921 - val_accuracy: 0.5430\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 1.2516 - accuracy: 0.5643 - val_loss: 1.3386 - val_accuracy: 0.5629\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 12s 325ms/step - loss: 1.2194 - accuracy: 0.5726 - val_loss: 1.4153 - val_accuracy: 0.5331\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 1.2997 - accuracy: 0.5560 - val_loss: 1.3920 - val_accuracy: 0.5397\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 13s 328ms/step - loss: 1.2569 - accuracy: 0.5552 - val_loss: 1.3499 - val_accuracy: 0.5298\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 1.2494 - accuracy: 0.5776 - val_loss: 1.3483 - val_accuracy: 0.5530\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 11s 280ms/step - loss: 1.2375 - accuracy: 0.5552 - val_loss: 1.2937 - val_accuracy: 0.5662\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 1.2478 - accuracy: 0.5718 - val_loss: 1.2753 - val_accuracy: 0.5728\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 11s 280ms/step - loss: 1.2112 - accuracy: 0.5668 - val_loss: 1.2965 - val_accuracy: 0.5596\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 10s 263ms/step - loss: 1.2095 - accuracy: 0.5743 - val_loss: 1.3067 - val_accuracy: 0.5331\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 11s 280ms/step - loss: 1.2118 - accuracy: 0.5842 - val_loss: 1.3358 - val_accuracy: 0.5695\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 14s 369ms/step - loss: 1.2347 - accuracy: 0.5577 - val_loss: 1.3009 - val_accuracy: 0.5762\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 14s 369ms/step - loss: 1.1771 - accuracy: 0.5867 - val_loss: 1.4075 - val_accuracy: 0.5430\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 14s 358ms/step - loss: 1.1561 - accuracy: 0.5934 - val_loss: 1.4033 - val_accuracy: 0.5728\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 1.2211 - accuracy: 0.5751 - val_loss: 1.3435 - val_accuracy: 0.5166\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 13s 334ms/step - loss: 1.2376 - accuracy: 0.5469 - val_loss: 1.3022 - val_accuracy: 0.5596\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 13s 353ms/step - loss: 1.1910 - accuracy: 0.5768 - val_loss: 1.3806 - val_accuracy: 0.5199\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 14s 366ms/step - loss: 1.1661 - accuracy: 0.5751 - val_loss: 1.2796 - val_accuracy: 0.5861\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.1738 - accuracy: 0.5842 - val_loss: 1.2564 - val_accuracy: 0.5563\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 14s 361ms/step - loss: 1.1494 - accuracy: 0.5967 - val_loss: 1.2462 - val_accuracy: 0.5960\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 13s 345ms/step - loss: 1.1425 - accuracy: 0.5992 - val_loss: 1.2106 - val_accuracy: 0.6026\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.1040 - accuracy: 0.5983 - val_loss: 1.1959 - val_accuracy: 0.6126\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.1573 - accuracy: 0.5967 - val_loss: 1.2415 - val_accuracy: 0.5960\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.2219 - accuracy: 0.5544 - val_loss: 1.2168 - val_accuracy: 0.5960\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 14s 368ms/step - loss: 1.1032 - accuracy: 0.6041 - val_loss: 1.2791 - val_accuracy: 0.5629\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.1264 - accuracy: 0.5992 - val_loss: 1.1638 - val_accuracy: 0.6060\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 1.1419 - accuracy: 0.5992 - val_loss: 1.2209 - val_accuracy: 0.6060\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.1474 - accuracy: 0.5950 - val_loss: 1.1349 - val_accuracy: 0.6026\n",
      "10/10 [==============================] - 1s 59ms/step\n",
      "Fold 2\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 15s 364ms/step - loss: 27.8828 - accuracy: 0.1568 - val_loss: 2.3027 - val_accuracy: 0.1954\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 2.1477 - accuracy: 0.2033 - val_loss: 2.1692 - val_accuracy: 0.2119\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 14s 373ms/step - loss: 2.1083 - accuracy: 0.2282 - val_loss: 2.1592 - val_accuracy: 0.2417\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 2.0859 - accuracy: 0.2440 - val_loss: 2.1096 - val_accuracy: 0.2417\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 13s 345ms/step - loss: 2.0353 - accuracy: 0.2747 - val_loss: 2.0415 - val_accuracy: 0.2583\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 2.0087 - accuracy: 0.2813 - val_loss: 2.0259 - val_accuracy: 0.2781\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.9838 - accuracy: 0.2705 - val_loss: 1.9912 - val_accuracy: 0.3179\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.9458 - accuracy: 0.3029 - val_loss: 2.0627 - val_accuracy: 0.2815\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 14s 350ms/step - loss: 1.9597 - accuracy: 0.3004 - val_loss: 2.0250 - val_accuracy: 0.2682\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 13s 336ms/step - loss: 1.9514 - accuracy: 0.2838 - val_loss: 2.0007 - val_accuracy: 0.3013\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.9117 - accuracy: 0.3203 - val_loss: 1.9524 - val_accuracy: 0.3046\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.8910 - accuracy: 0.3220 - val_loss: 1.9438 - val_accuracy: 0.3113\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 13s 352ms/step - loss: 1.8745 - accuracy: 0.3195 - val_loss: 1.8958 - val_accuracy: 0.3212\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 1.8486 - accuracy: 0.3311 - val_loss: 1.8952 - val_accuracy: 0.3576\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.8325 - accuracy: 0.3344 - val_loss: 1.8201 - val_accuracy: 0.3510\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.8138 - accuracy: 0.3494 - val_loss: 1.7822 - val_accuracy: 0.3344\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.8544 - accuracy: 0.3154 - val_loss: 1.8092 - val_accuracy: 0.3344\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 14s 361ms/step - loss: 1.8083 - accuracy: 0.3618 - val_loss: 1.8010 - val_accuracy: 0.3642\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.7818 - accuracy: 0.3685 - val_loss: 1.7882 - val_accuracy: 0.3311\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 13s 352ms/step - loss: 1.7018 - accuracy: 0.4008 - val_loss: 1.7716 - val_accuracy: 0.3841\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 1.7666 - accuracy: 0.3577 - val_loss: 1.8000 - val_accuracy: 0.3907\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.7347 - accuracy: 0.3618 - val_loss: 1.7098 - val_accuracy: 0.3974\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.6843 - accuracy: 0.3909 - val_loss: 1.6933 - val_accuracy: 0.4139\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 1.7050 - accuracy: 0.4000 - val_loss: 1.6360 - val_accuracy: 0.4040\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 1.6646 - accuracy: 0.4141 - val_loss: 1.5922 - val_accuracy: 0.4371\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.6747 - accuracy: 0.4124 - val_loss: 1.6544 - val_accuracy: 0.3808\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.6867 - accuracy: 0.3934 - val_loss: 1.6712 - val_accuracy: 0.4536\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 1.6520 - accuracy: 0.4224 - val_loss: 1.7179 - val_accuracy: 0.4470\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 1.6548 - accuracy: 0.4133 - val_loss: 1.6263 - val_accuracy: 0.4338\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 13s 345ms/step - loss: 1.5957 - accuracy: 0.4398 - val_loss: 1.6576 - val_accuracy: 0.4470\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.5991 - accuracy: 0.4307 - val_loss: 1.5972 - val_accuracy: 0.4338\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.6244 - accuracy: 0.4174 - val_loss: 1.6627 - val_accuracy: 0.3974\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.5939 - accuracy: 0.4274 - val_loss: 1.8019 - val_accuracy: 0.4272\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.5752 - accuracy: 0.4423 - val_loss: 1.6889 - val_accuracy: 0.4172\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 1.5794 - accuracy: 0.4498 - val_loss: 1.6740 - val_accuracy: 0.4338\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.5471 - accuracy: 0.4598 - val_loss: 1.6630 - val_accuracy: 0.4040\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.5745 - accuracy: 0.4448 - val_loss: 1.7652 - val_accuracy: 0.4172\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.5258 - accuracy: 0.4556 - val_loss: 1.6311 - val_accuracy: 0.4338\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.5231 - accuracy: 0.4672 - val_loss: 1.6358 - val_accuracy: 0.4205\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.5213 - accuracy: 0.4581 - val_loss: 1.5480 - val_accuracy: 0.4570\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 13s 328ms/step - loss: 1.5237 - accuracy: 0.4382 - val_loss: 1.5881 - val_accuracy: 0.4305\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 13s 351ms/step - loss: 1.4876 - accuracy: 0.4730 - val_loss: 1.5891 - val_accuracy: 0.4636\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.5247 - accuracy: 0.4647 - val_loss: 1.5534 - val_accuracy: 0.4470\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.5260 - accuracy: 0.4515 - val_loss: 1.5646 - val_accuracy: 0.4371\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.5071 - accuracy: 0.4672 - val_loss: 1.5601 - val_accuracy: 0.4305\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.4935 - accuracy: 0.4656 - val_loss: 1.5461 - val_accuracy: 0.4139\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 1.4773 - accuracy: 0.4780 - val_loss: 1.5063 - val_accuracy: 0.4503\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.4783 - accuracy: 0.4631 - val_loss: 1.5371 - val_accuracy: 0.4702\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.5047 - accuracy: 0.4490 - val_loss: 1.5456 - val_accuracy: 0.4603\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.4621 - accuracy: 0.4838 - val_loss: 1.4780 - val_accuracy: 0.4735\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.4218 - accuracy: 0.4913 - val_loss: 1.4965 - val_accuracy: 0.4735\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4355 - accuracy: 0.4664 - val_loss: 1.4719 - val_accuracy: 0.4702\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4594 - accuracy: 0.4622 - val_loss: 1.4405 - val_accuracy: 0.4801\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 13s 336ms/step - loss: 1.4941 - accuracy: 0.4680 - val_loss: 1.4774 - val_accuracy: 0.4536\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.4661 - accuracy: 0.4672 - val_loss: 1.4415 - val_accuracy: 0.4768\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.4166 - accuracy: 0.4888 - val_loss: 1.4591 - val_accuracy: 0.4801\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.4347 - accuracy: 0.4805 - val_loss: 1.4120 - val_accuracy: 0.4967\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 14s 367ms/step - loss: 1.4183 - accuracy: 0.4963 - val_loss: 1.4440 - val_accuracy: 0.4801\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.4338 - accuracy: 0.4888 - val_loss: 1.4700 - val_accuracy: 0.4801\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.4451 - accuracy: 0.4763 - val_loss: 1.3972 - val_accuracy: 0.5099\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.4389 - accuracy: 0.4863 - val_loss: 1.3936 - val_accuracy: 0.5066\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 14s 349ms/step - loss: 1.3937 - accuracy: 0.5021 - val_loss: 1.3892 - val_accuracy: 0.4868\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 14s 359ms/step - loss: 1.4247 - accuracy: 0.4830 - val_loss: 1.4300 - val_accuracy: 0.4570\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 1.4139 - accuracy: 0.4846 - val_loss: 1.4372 - val_accuracy: 0.5099\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.3509 - accuracy: 0.5037 - val_loss: 1.4991 - val_accuracy: 0.5331\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.3658 - accuracy: 0.5112 - val_loss: 1.4075 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.3884 - accuracy: 0.5129 - val_loss: 1.4662 - val_accuracy: 0.4801\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.4073 - accuracy: 0.5278 - val_loss: 1.4586 - val_accuracy: 0.4901\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 11s 298ms/step - loss: 1.3490 - accuracy: 0.5178 - val_loss: 1.4948 - val_accuracy: 0.5066\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 1.3737 - accuracy: 0.5037 - val_loss: 1.3928 - val_accuracy: 0.5232\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 1.3816 - accuracy: 0.4855 - val_loss: 1.5698 - val_accuracy: 0.4735\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.3631 - accuracy: 0.5071 - val_loss: 1.4290 - val_accuracy: 0.4801\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.3996 - accuracy: 0.5112 - val_loss: 1.4326 - val_accuracy: 0.5232\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.3470 - accuracy: 0.5253 - val_loss: 1.4053 - val_accuracy: 0.5265\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 13s 329ms/step - loss: 1.3109 - accuracy: 0.5353 - val_loss: 1.4431 - val_accuracy: 0.4967\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.3252 - accuracy: 0.5046 - val_loss: 1.5272 - val_accuracy: 0.4967\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 1.3545 - accuracy: 0.5178 - val_loss: 1.4139 - val_accuracy: 0.5265\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 11s 283ms/step - loss: 1.3438 - accuracy: 0.5203 - val_loss: 1.3244 - val_accuracy: 0.5364\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 11s 288ms/step - loss: 1.3661 - accuracy: 0.5029 - val_loss: 1.4182 - val_accuracy: 0.5199\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 10s 270ms/step - loss: 1.3279 - accuracy: 0.5104 - val_loss: 1.4120 - val_accuracy: 0.4868\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 11s 273ms/step - loss: 1.3336 - accuracy: 0.5203 - val_loss: 1.3954 - val_accuracy: 0.5497\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 11s 283ms/step - loss: 1.2970 - accuracy: 0.5212 - val_loss: 1.4182 - val_accuracy: 0.5033\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 11s 283ms/step - loss: 1.2837 - accuracy: 0.5436 - val_loss: 1.5250 - val_accuracy: 0.4901\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 11s 273ms/step - loss: 1.3194 - accuracy: 0.5369 - val_loss: 1.3554 - val_accuracy: 0.5497\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 12s 299ms/step - loss: 1.2554 - accuracy: 0.5577 - val_loss: 1.3965 - val_accuracy: 0.5166\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 11s 283ms/step - loss: 1.2953 - accuracy: 0.5394 - val_loss: 1.3202 - val_accuracy: 0.5464\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 11s 288ms/step - loss: 1.2899 - accuracy: 0.5469 - val_loss: 1.5948 - val_accuracy: 0.4702\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 11s 298ms/step - loss: 1.2835 - accuracy: 0.5286 - val_loss: 1.3711 - val_accuracy: 0.5530\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 1.2869 - accuracy: 0.5228 - val_loss: 1.3334 - val_accuracy: 0.5298\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 12s 304ms/step - loss: 1.2877 - accuracy: 0.5311 - val_loss: 1.3721 - val_accuracy: 0.5397\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 12s 302ms/step - loss: 1.3276 - accuracy: 0.5120 - val_loss: 1.4461 - val_accuracy: 0.5298\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 1.3859 - accuracy: 0.5253 - val_loss: 1.3428 - val_accuracy: 0.5397\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 11s 298ms/step - loss: 1.2824 - accuracy: 0.5320 - val_loss: 1.3286 - val_accuracy: 0.5232\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 12s 311ms/step - loss: 1.2213 - accuracy: 0.5701 - val_loss: 1.3417 - val_accuracy: 0.5331\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 12s 307ms/step - loss: 1.2211 - accuracy: 0.5718 - val_loss: 1.3790 - val_accuracy: 0.5497\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 1.2634 - accuracy: 0.5710 - val_loss: 1.3624 - val_accuracy: 0.5397\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 1.2341 - accuracy: 0.5577 - val_loss: 1.3996 - val_accuracy: 0.5364\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 1.2545 - accuracy: 0.5502 - val_loss: 1.3342 - val_accuracy: 0.5298\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 12s 312ms/step - loss: 1.2438 - accuracy: 0.5502 - val_loss: 1.5842 - val_accuracy: 0.5099\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 11s 293ms/step - loss: 1.2635 - accuracy: 0.5436 - val_loss: 1.1953 - val_accuracy: 0.5795\n",
      "10/10 [==============================] - 1s 52ms/step\n",
      "Fold 3\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 14s 318ms/step - loss: 52.7074 - accuracy: 0.1401 - val_loss: 2.2907 - val_accuracy: 0.1761\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 2.2193 - accuracy: 0.1791 - val_loss: 2.1819 - val_accuracy: 0.1960\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 12s 301ms/step - loss: 2.1604 - accuracy: 0.2098 - val_loss: 2.1343 - val_accuracy: 0.2226\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 2.1554 - accuracy: 0.2056 - val_loss: 2.1129 - val_accuracy: 0.2292\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 11s 298ms/step - loss: 2.1282 - accuracy: 0.2289 - val_loss: 2.0948 - val_accuracy: 0.2193\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 11s 291ms/step - loss: 2.1239 - accuracy: 0.2156 - val_loss: 2.0958 - val_accuracy: 0.2193\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 12s 310ms/step - loss: 2.1217 - accuracy: 0.2231 - val_loss: 2.1009 - val_accuracy: 0.2392\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 2.1215 - accuracy: 0.2139 - val_loss: 2.0829 - val_accuracy: 0.2259\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 2.0979 - accuracy: 0.2181 - val_loss: 2.0652 - val_accuracy: 0.2458\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 12s 300ms/step - loss: 2.0901 - accuracy: 0.2189 - val_loss: 2.0565 - val_accuracy: 0.2425\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 12s 320ms/step - loss: 2.0730 - accuracy: 0.2338 - val_loss: 2.0883 - val_accuracy: 0.2392\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 12s 313ms/step - loss: 2.0743 - accuracy: 0.2421 - val_loss: 2.0747 - val_accuracy: 0.2558\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 2.0699 - accuracy: 0.2396 - val_loss: 2.0619 - val_accuracy: 0.2525\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 12s 301ms/step - loss: 2.0525 - accuracy: 0.2512 - val_loss: 2.0537 - val_accuracy: 0.2525\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 2.0826 - accuracy: 0.2446 - val_loss: 2.0582 - val_accuracy: 0.2625\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 12s 307ms/step - loss: 2.0447 - accuracy: 0.2421 - val_loss: 2.1140 - val_accuracy: 0.2658\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 12s 312ms/step - loss: 2.0710 - accuracy: 0.2388 - val_loss: 2.0542 - val_accuracy: 0.2591\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 12s 310ms/step - loss: 2.0173 - accuracy: 0.2687 - val_loss: 2.0633 - val_accuracy: 0.2658\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 2.0559 - accuracy: 0.2388 - val_loss: 2.0661 - val_accuracy: 0.2458\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 2.0520 - accuracy: 0.2512 - val_loss: 2.0577 - val_accuracy: 0.3156\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 12s 312ms/step - loss: 1.9931 - accuracy: 0.2886 - val_loss: 2.0316 - val_accuracy: 0.2824\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 11s 291ms/step - loss: 2.0164 - accuracy: 0.2620 - val_loss: 2.0603 - val_accuracy: 0.2957\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 12s 309ms/step - loss: 2.0279 - accuracy: 0.2620 - val_loss: 2.0278 - val_accuracy: 0.3056\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 12s 317ms/step - loss: 1.9899 - accuracy: 0.2595 - val_loss: 1.9607 - val_accuracy: 0.3090\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 1.9819 - accuracy: 0.2728 - val_loss: 2.0450 - val_accuracy: 0.3156\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 1.9680 - accuracy: 0.2877 - val_loss: 2.0792 - val_accuracy: 0.3223\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 2.0022 - accuracy: 0.2695 - val_loss: 1.9232 - val_accuracy: 0.3289\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 1.9661 - accuracy: 0.2927 - val_loss: 1.9224 - val_accuracy: 0.3289\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 11s 275ms/step - loss: 1.9543 - accuracy: 0.2910 - val_loss: 1.9138 - val_accuracy: 0.3056\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 11s 273ms/step - loss: 1.9344 - accuracy: 0.2861 - val_loss: 2.0587 - val_accuracy: 0.3754\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 1.9410 - accuracy: 0.3035 - val_loss: 1.9343 - val_accuracy: 0.3322\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 10s 269ms/step - loss: 1.9035 - accuracy: 0.3043 - val_loss: 1.9003 - val_accuracy: 0.3223\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 1.8963 - accuracy: 0.3118 - val_loss: 1.8499 - val_accuracy: 0.3555\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 11s 274ms/step - loss: 1.8218 - accuracy: 0.3325 - val_loss: 1.8910 - val_accuracy: 0.3455\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 1.9018 - accuracy: 0.3151 - val_loss: 1.8346 - val_accuracy: 0.3156\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 1.8887 - accuracy: 0.3068 - val_loss: 1.8224 - val_accuracy: 0.3422\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.8788 - accuracy: 0.3076 - val_loss: 1.7459 - val_accuracy: 0.3754\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.8521 - accuracy: 0.3242 - val_loss: 1.8015 - val_accuracy: 0.3688\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 13s 333ms/step - loss: 1.8151 - accuracy: 0.3416 - val_loss: 1.8095 - val_accuracy: 0.3987\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.7948 - accuracy: 0.3474 - val_loss: 1.7917 - val_accuracy: 0.3787\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.8040 - accuracy: 0.3566 - val_loss: 1.8639 - val_accuracy: 0.3721\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.8132 - accuracy: 0.3226 - val_loss: 1.7435 - val_accuracy: 0.3920\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 13s 331ms/step - loss: 1.8146 - accuracy: 0.3458 - val_loss: 1.7337 - val_accuracy: 0.4086\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 1.7553 - accuracy: 0.3698 - val_loss: 1.6382 - val_accuracy: 0.4319\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.7803 - accuracy: 0.3648 - val_loss: 1.6991 - val_accuracy: 0.3953\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.7163 - accuracy: 0.3765 - val_loss: 1.6782 - val_accuracy: 0.4153\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 13s 338ms/step - loss: 1.7313 - accuracy: 0.3914 - val_loss: 1.6936 - val_accuracy: 0.4120\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 1.7297 - accuracy: 0.3847 - val_loss: 1.7626 - val_accuracy: 0.4186\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.7673 - accuracy: 0.3806 - val_loss: 1.6242 - val_accuracy: 0.4385\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 14s 354ms/step - loss: 1.7665 - accuracy: 0.3706 - val_loss: 1.8086 - val_accuracy: 0.3688\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 13s 333ms/step - loss: 1.6933 - accuracy: 0.3814 - val_loss: 1.7033 - val_accuracy: 0.4020\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.7211 - accuracy: 0.3839 - val_loss: 1.6821 - val_accuracy: 0.4219\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.6962 - accuracy: 0.3856 - val_loss: 1.5869 - val_accuracy: 0.4020\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.6932 - accuracy: 0.3955 - val_loss: 1.6434 - val_accuracy: 0.3920\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.6869 - accuracy: 0.3831 - val_loss: 1.6565 - val_accuracy: 0.4186\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.6444 - accuracy: 0.4270 - val_loss: 1.6508 - val_accuracy: 0.4120\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 14s 358ms/step - loss: 1.6843 - accuracy: 0.4088 - val_loss: 1.6488 - val_accuracy: 0.3887\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.6778 - accuracy: 0.4113 - val_loss: 1.6498 - val_accuracy: 0.4452\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.6325 - accuracy: 0.4121 - val_loss: 1.5728 - val_accuracy: 0.4385\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 1.6350 - accuracy: 0.4129 - val_loss: 1.5784 - val_accuracy: 0.4319\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.6986 - accuracy: 0.3964 - val_loss: 1.6000 - val_accuracy: 0.4651\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 1.6785 - accuracy: 0.3980 - val_loss: 1.6618 - val_accuracy: 0.4651\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.6269 - accuracy: 0.4312 - val_loss: 1.5925 - val_accuracy: 0.4718\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 14s 366ms/step - loss: 1.5971 - accuracy: 0.4295 - val_loss: 1.5780 - val_accuracy: 0.4518\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 14s 367ms/step - loss: 1.6052 - accuracy: 0.4353 - val_loss: 1.5487 - val_accuracy: 0.4751\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 14s 368ms/step - loss: 1.6009 - accuracy: 0.4312 - val_loss: 1.4936 - val_accuracy: 0.4850\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.6073 - accuracy: 0.4444 - val_loss: 1.6250 - val_accuracy: 0.4784\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.6159 - accuracy: 0.4237 - val_loss: 1.4962 - val_accuracy: 0.4784\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 14s 368ms/step - loss: 1.5930 - accuracy: 0.4212 - val_loss: 1.6037 - val_accuracy: 0.4153\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.6522 - accuracy: 0.4287 - val_loss: 1.6739 - val_accuracy: 0.4219\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.6460 - accuracy: 0.4370 - val_loss: 1.6281 - val_accuracy: 0.4485\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 1.5834 - accuracy: 0.4494 - val_loss: 1.6494 - val_accuracy: 0.4352\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 14s 359ms/step - loss: 1.5868 - accuracy: 0.4478 - val_loss: 1.5445 - val_accuracy: 0.4551\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 14s 354ms/step - loss: 1.5525 - accuracy: 0.4619 - val_loss: 1.5265 - val_accuracy: 0.4585\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 1.5802 - accuracy: 0.4469 - val_loss: 1.5991 - val_accuracy: 0.4684\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 11s 294ms/step - loss: 1.5905 - accuracy: 0.4370 - val_loss: 1.5460 - val_accuracy: 0.4252\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 13s 330ms/step - loss: 1.5607 - accuracy: 0.4478 - val_loss: 1.4538 - val_accuracy: 0.5249\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 14s 350ms/step - loss: 1.5283 - accuracy: 0.4561 - val_loss: 1.4300 - val_accuracy: 0.5017\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 1.5077 - accuracy: 0.4585 - val_loss: 1.5587 - val_accuracy: 0.4751\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.5591 - accuracy: 0.4552 - val_loss: 1.5954 - val_accuracy: 0.4684\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.5842 - accuracy: 0.4511 - val_loss: 1.5017 - val_accuracy: 0.4718\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.5447 - accuracy: 0.4527 - val_loss: 1.5342 - val_accuracy: 0.4651\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 14s 358ms/step - loss: 1.5674 - accuracy: 0.4337 - val_loss: 1.4824 - val_accuracy: 0.5116\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.5397 - accuracy: 0.4660 - val_loss: 1.5379 - val_accuracy: 0.4850\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 14s 379ms/step - loss: 1.4910 - accuracy: 0.4793 - val_loss: 1.5013 - val_accuracy: 0.4751\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 16s 405ms/step - loss: 1.5347 - accuracy: 0.4627 - val_loss: 1.4338 - val_accuracy: 0.5150\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 1.5089 - accuracy: 0.4602 - val_loss: 1.5227 - val_accuracy: 0.4850\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 15s 397ms/step - loss: 1.5127 - accuracy: 0.4569 - val_loss: 1.4120 - val_accuracy: 0.5017\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 1.5378 - accuracy: 0.4569 - val_loss: 1.6057 - val_accuracy: 0.4718\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 15s 401ms/step - loss: 1.4593 - accuracy: 0.4826 - val_loss: 1.4514 - val_accuracy: 0.5183\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 1.4822 - accuracy: 0.4892 - val_loss: 1.4244 - val_accuracy: 0.5050\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 1.5785 - accuracy: 0.4486 - val_loss: 1.4043 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 1.4508 - accuracy: 0.4643 - val_loss: 1.3858 - val_accuracy: 0.4983\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 1.4426 - accuracy: 0.4900 - val_loss: 1.3865 - val_accuracy: 0.5050\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 1.5011 - accuracy: 0.4784 - val_loss: 1.3784 - val_accuracy: 0.5017\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 14s 369ms/step - loss: 1.5095 - accuracy: 0.4892 - val_loss: 1.4353 - val_accuracy: 0.4983\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 15s 385ms/step - loss: 1.4646 - accuracy: 0.4718 - val_loss: 1.6381 - val_accuracy: 0.5017\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 15s 378ms/step - loss: 1.5003 - accuracy: 0.4842 - val_loss: 1.4754 - val_accuracy: 0.4452\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 14s 379ms/step - loss: 1.4373 - accuracy: 0.5058 - val_loss: 1.6348 - val_accuracy: 0.4950\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 13s 334ms/step - loss: 1.4561 - accuracy: 0.4834 - val_loss: 1.4836 - val_accuracy: 0.5183\n",
      "10/10 [==============================] - 1s 58ms/step\n",
      "Fold 4\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 18s 410ms/step - loss: 15.0315 - accuracy: 0.1609 - val_loss: 2.1229 - val_accuracy: 0.2159\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 15s 375ms/step - loss: 2.1035 - accuracy: 0.2222 - val_loss: 2.0306 - val_accuracy: 0.2126\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 14s 377ms/step - loss: 2.0460 - accuracy: 0.2504 - val_loss: 2.0521 - val_accuracy: 0.2625\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 14s 361ms/step - loss: 1.9657 - accuracy: 0.2927 - val_loss: 1.9036 - val_accuracy: 0.2757\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 13s 351ms/step - loss: 1.9315 - accuracy: 0.3151 - val_loss: 1.8704 - val_accuracy: 0.3787\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 1.8744 - accuracy: 0.3267 - val_loss: 1.8232 - val_accuracy: 0.3654\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 1.8502 - accuracy: 0.3458 - val_loss: 1.7842 - val_accuracy: 0.3721\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 14s 364ms/step - loss: 1.8378 - accuracy: 0.3408 - val_loss: 1.8085 - val_accuracy: 0.3555\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 1.8362 - accuracy: 0.3549 - val_loss: 1.7777 - val_accuracy: 0.3422\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 13s 331ms/step - loss: 1.7343 - accuracy: 0.3856 - val_loss: 1.7257 - val_accuracy: 0.3920\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 1.6964 - accuracy: 0.4046 - val_loss: 1.6659 - val_accuracy: 0.3920\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.7145 - accuracy: 0.3905 - val_loss: 1.7568 - val_accuracy: 0.3920\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 14s 364ms/step - loss: 1.6335 - accuracy: 0.4129 - val_loss: 1.6644 - val_accuracy: 0.4219\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 1.6628 - accuracy: 0.4138 - val_loss: 1.5707 - val_accuracy: 0.4352\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 1.6349 - accuracy: 0.4121 - val_loss: 1.5623 - val_accuracy: 0.4053\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.6119 - accuracy: 0.4295 - val_loss: 1.6532 - val_accuracy: 0.4319\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.6112 - accuracy: 0.4154 - val_loss: 1.6329 - val_accuracy: 0.4186\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 1.6178 - accuracy: 0.4063 - val_loss: 1.5496 - val_accuracy: 0.4718\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.5681 - accuracy: 0.4478 - val_loss: 1.5503 - val_accuracy: 0.4585\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 14s 379ms/step - loss: 1.5392 - accuracy: 0.4602 - val_loss: 1.5689 - val_accuracy: 0.4319\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 1.6531 - accuracy: 0.4022 - val_loss: 1.5554 - val_accuracy: 0.4153\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.5899 - accuracy: 0.4370 - val_loss: 1.4927 - val_accuracy: 0.4585\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 1.5402 - accuracy: 0.4353 - val_loss: 1.5283 - val_accuracy: 0.4419\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 15s 382ms/step - loss: 1.4943 - accuracy: 0.4478 - val_loss: 1.4956 - val_accuracy: 0.4751\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 1.4959 - accuracy: 0.4635 - val_loss: 1.4641 - val_accuracy: 0.4751\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 15s 395ms/step - loss: 1.4630 - accuracy: 0.4784 - val_loss: 1.4447 - val_accuracy: 0.5116\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 15s 382ms/step - loss: 1.4822 - accuracy: 0.4876 - val_loss: 1.4134 - val_accuracy: 0.4651\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 15s 378ms/step - loss: 1.5017 - accuracy: 0.4610 - val_loss: 1.5350 - val_accuracy: 0.4718\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 1.4843 - accuracy: 0.4859 - val_loss: 1.5002 - val_accuracy: 0.5050\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 14s 354ms/step - loss: 1.4533 - accuracy: 0.4726 - val_loss: 1.4355 - val_accuracy: 0.5515\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4913 - accuracy: 0.4735 - val_loss: 1.4842 - val_accuracy: 0.4983\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 1.4108 - accuracy: 0.4884 - val_loss: 1.4038 - val_accuracy: 0.5415\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.4297 - accuracy: 0.5091 - val_loss: 1.3816 - val_accuracy: 0.5183\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.4057 - accuracy: 0.4917 - val_loss: 1.4619 - val_accuracy: 0.4551\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 14s 372ms/step - loss: 1.4217 - accuracy: 0.4925 - val_loss: 1.5141 - val_accuracy: 0.4751\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 14s 368ms/step - loss: 1.3916 - accuracy: 0.4900 - val_loss: 1.4187 - val_accuracy: 0.5050\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 14s 374ms/step - loss: 1.3595 - accuracy: 0.5315 - val_loss: 1.3744 - val_accuracy: 0.5415\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 14s 364ms/step - loss: 1.3732 - accuracy: 0.5133 - val_loss: 1.3769 - val_accuracy: 0.5482\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 15s 375ms/step - loss: 1.4215 - accuracy: 0.4942 - val_loss: 1.4309 - val_accuracy: 0.5415\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 14s 366ms/step - loss: 1.4433 - accuracy: 0.5050 - val_loss: 1.4303 - val_accuracy: 0.5249\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 14s 368ms/step - loss: 1.3934 - accuracy: 0.5158 - val_loss: 1.4551 - val_accuracy: 0.5216\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 1.3460 - accuracy: 0.5431 - val_loss: 1.3945 - val_accuracy: 0.5083\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.3974 - accuracy: 0.5100 - val_loss: 1.3564 - val_accuracy: 0.5216\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.3519 - accuracy: 0.5357 - val_loss: 1.3609 - val_accuracy: 0.5282\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 13s 345ms/step - loss: 1.3535 - accuracy: 0.5174 - val_loss: 1.3420 - val_accuracy: 0.5282\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 13s 330ms/step - loss: 1.3603 - accuracy: 0.5174 - val_loss: 1.5460 - val_accuracy: 0.4718\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.3841 - accuracy: 0.5050 - val_loss: 1.3502 - val_accuracy: 0.5449\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 1.3659 - accuracy: 0.5207 - val_loss: 1.2877 - val_accuracy: 0.5382\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 1.3259 - accuracy: 0.5166 - val_loss: 1.4467 - val_accuracy: 0.5515\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 9s 233ms/step - loss: 1.3513 - accuracy: 0.5182 - val_loss: 1.3111 - val_accuracy: 0.5914\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 11s 281ms/step - loss: 1.3303 - accuracy: 0.5415 - val_loss: 1.3005 - val_accuracy: 0.5415\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 1.2856 - accuracy: 0.5506 - val_loss: 1.2571 - val_accuracy: 0.5482\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.2979 - accuracy: 0.5390 - val_loss: 1.3070 - val_accuracy: 0.5548\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 11s 285ms/step - loss: 1.3133 - accuracy: 0.5373 - val_loss: 1.5457 - val_accuracy: 0.4718\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 10s 274ms/step - loss: 1.3235 - accuracy: 0.5274 - val_loss: 1.3141 - val_accuracy: 0.5415\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 11s 277ms/step - loss: 1.2618 - accuracy: 0.5589 - val_loss: 1.2987 - val_accuracy: 0.5150\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 11s 270ms/step - loss: 1.3212 - accuracy: 0.5282 - val_loss: 1.3002 - val_accuracy: 0.5947\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 10s 274ms/step - loss: 1.3099 - accuracy: 0.5423 - val_loss: 1.2447 - val_accuracy: 0.5880\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 11s 281ms/step - loss: 1.2547 - accuracy: 0.5663 - val_loss: 1.2606 - val_accuracy: 0.5681\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 10s 269ms/step - loss: 1.2780 - accuracy: 0.5448 - val_loss: 1.3417 - val_accuracy: 0.5449\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 10s 271ms/step - loss: 1.2732 - accuracy: 0.5390 - val_loss: 1.2251 - val_accuracy: 0.5847\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 11s 276ms/step - loss: 1.2573 - accuracy: 0.5647 - val_loss: 1.2466 - val_accuracy: 0.5681\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 11s 282ms/step - loss: 1.2507 - accuracy: 0.5580 - val_loss: 1.2661 - val_accuracy: 0.5648\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 1.3061 - accuracy: 0.5381 - val_loss: 1.2896 - val_accuracy: 0.5714\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 1.2772 - accuracy: 0.5406 - val_loss: 1.2949 - val_accuracy: 0.5415\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 10s 268ms/step - loss: 1.2239 - accuracy: 0.5721 - val_loss: 1.2692 - val_accuracy: 0.5581\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 11s 282ms/step - loss: 1.2511 - accuracy: 0.5564 - val_loss: 1.3087 - val_accuracy: 0.5581\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 11s 275ms/step - loss: 1.2178 - accuracy: 0.5713 - val_loss: 1.2254 - val_accuracy: 0.5482\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 11s 275ms/step - loss: 1.1969 - accuracy: 0.5796 - val_loss: 1.1857 - val_accuracy: 0.6080\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 11s 277ms/step - loss: 1.2562 - accuracy: 0.5663 - val_loss: 1.1713 - val_accuracy: 0.5947\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 11s 280ms/step - loss: 1.2495 - accuracy: 0.5464 - val_loss: 1.1589 - val_accuracy: 0.6246\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 1.2137 - accuracy: 0.5680 - val_loss: 1.1650 - val_accuracy: 0.6013\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 11s 275ms/step - loss: 1.2028 - accuracy: 0.5746 - val_loss: 1.3755 - val_accuracy: 0.5316\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 11s 279ms/step - loss: 1.1758 - accuracy: 0.5663 - val_loss: 1.2290 - val_accuracy: 0.5581\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 10s 268ms/step - loss: 1.1995 - accuracy: 0.5788 - val_loss: 1.2816 - val_accuracy: 0.5781\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 1.2327 - accuracy: 0.5572 - val_loss: 1.2455 - val_accuracy: 0.5282\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 1.2180 - accuracy: 0.5564 - val_loss: 1.2825 - val_accuracy: 0.5581\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 11s 276ms/step - loss: 1.1816 - accuracy: 0.5837 - val_loss: 1.1252 - val_accuracy: 0.6113\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 10s 273ms/step - loss: 1.2112 - accuracy: 0.5713 - val_loss: 1.1447 - val_accuracy: 0.6113\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 10s 271ms/step - loss: 1.1423 - accuracy: 0.6028 - val_loss: 1.1690 - val_accuracy: 0.6080\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 10s 264ms/step - loss: 1.2325 - accuracy: 0.5514 - val_loss: 1.2177 - val_accuracy: 0.5847\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 11s 275ms/step - loss: 1.1393 - accuracy: 0.6036 - val_loss: 1.2290 - val_accuracy: 0.6080\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 1.1828 - accuracy: 0.5829 - val_loss: 1.1545 - val_accuracy: 0.6246\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 1.2217 - accuracy: 0.5804 - val_loss: 1.1758 - val_accuracy: 0.6113\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 11s 280ms/step - loss: 1.1574 - accuracy: 0.5862 - val_loss: 1.2537 - val_accuracy: 0.6113\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 11s 282ms/step - loss: 1.1777 - accuracy: 0.5779 - val_loss: 1.2054 - val_accuracy: 0.5648\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 1.2575 - accuracy: 0.5531 - val_loss: 1.2282 - val_accuracy: 0.5714\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 10s 269ms/step - loss: 1.1899 - accuracy: 0.5763 - val_loss: 1.2794 - val_accuracy: 0.5681\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 10s 271ms/step - loss: 1.2393 - accuracy: 0.5663 - val_loss: 1.1695 - val_accuracy: 0.6113\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 10s 268ms/step - loss: 1.1831 - accuracy: 0.5904 - val_loss: 1.2342 - val_accuracy: 0.5947\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 10s 270ms/step - loss: 1.1718 - accuracy: 0.5763 - val_loss: 1.1540 - val_accuracy: 0.6146\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 10s 265ms/step - loss: 1.2098 - accuracy: 0.5871 - val_loss: 1.2686 - val_accuracy: 0.5581\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 10s 266ms/step - loss: 1.2605 - accuracy: 0.5522 - val_loss: 1.4493 - val_accuracy: 0.5548\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 12s 302ms/step - loss: 1.1774 - accuracy: 0.5755 - val_loss: 1.1198 - val_accuracy: 0.6146\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 1.2085 - accuracy: 0.5771 - val_loss: 1.1247 - val_accuracy: 0.6312\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.1333 - accuracy: 0.5937 - val_loss: 1.1369 - val_accuracy: 0.6113\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 1.1569 - accuracy: 0.5920 - val_loss: 1.1993 - val_accuracy: 0.6146\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 13s 349ms/step - loss: 1.1650 - accuracy: 0.5854 - val_loss: 1.2602 - val_accuracy: 0.6047\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.1147 - accuracy: 0.6086 - val_loss: 1.2394 - val_accuracy: 0.5947\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.0771 - accuracy: 0.6186 - val_loss: 1.3220 - val_accuracy: 0.5714\n",
      "10/10 [==============================] - 1s 60ms/step\n",
      "Fold 5\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 16s 374ms/step - loss: 14.7480 - accuracy: 0.1534 - val_loss: 2.1950 - val_accuracy: 0.2159\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 2.1359 - accuracy: 0.2189 - val_loss: 2.0819 - val_accuracy: 0.2326\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 2.1001 - accuracy: 0.2172 - val_loss: 2.1026 - val_accuracy: 0.2359\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 2.0682 - accuracy: 0.2479 - val_loss: 2.0724 - val_accuracy: 0.2591\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 2.0505 - accuracy: 0.2504 - val_loss: 1.9732 - val_accuracy: 0.3256\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 13s 351ms/step - loss: 1.9946 - accuracy: 0.2828 - val_loss: 1.9689 - val_accuracy: 0.3056\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 2.0221 - accuracy: 0.2886 - val_loss: 1.8229 - val_accuracy: 0.3721\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.9506 - accuracy: 0.3060 - val_loss: 1.8521 - val_accuracy: 0.3522\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 14s 369ms/step - loss: 1.9668 - accuracy: 0.2977 - val_loss: 1.7777 - val_accuracy: 0.3688\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.9293 - accuracy: 0.3068 - val_loss: 1.8402 - val_accuracy: 0.3920\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 14s 350ms/step - loss: 1.9305 - accuracy: 0.3109 - val_loss: 1.8918 - val_accuracy: 0.3555\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.8889 - accuracy: 0.3226 - val_loss: 1.6813 - val_accuracy: 0.4385\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.9067 - accuracy: 0.3192 - val_loss: 1.9354 - val_accuracy: 0.3289\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.9544 - accuracy: 0.3134 - val_loss: 1.7367 - val_accuracy: 0.3987\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.8475 - accuracy: 0.3466 - val_loss: 1.7216 - val_accuracy: 0.4286\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 14s 364ms/step - loss: 1.8389 - accuracy: 0.3690 - val_loss: 1.6911 - val_accuracy: 0.4286\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 13s 352ms/step - loss: 1.8266 - accuracy: 0.3607 - val_loss: 1.7104 - val_accuracy: 0.4352\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.8157 - accuracy: 0.3416 - val_loss: 1.6698 - val_accuracy: 0.4120\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.8153 - accuracy: 0.3599 - val_loss: 1.6886 - val_accuracy: 0.4153\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.7801 - accuracy: 0.3640 - val_loss: 1.7279 - val_accuracy: 0.3787\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 14s 368ms/step - loss: 1.8005 - accuracy: 0.3574 - val_loss: 1.7056 - val_accuracy: 0.3654\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 14s 361ms/step - loss: 1.7827 - accuracy: 0.3574 - val_loss: 1.6519 - val_accuracy: 0.4186\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.7725 - accuracy: 0.3756 - val_loss: 1.5742 - val_accuracy: 0.4651\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 1.7474 - accuracy: 0.3847 - val_loss: 1.6537 - val_accuracy: 0.4452\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.7307 - accuracy: 0.3690 - val_loss: 1.6017 - val_accuracy: 0.4419\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 14s 369ms/step - loss: 1.7299 - accuracy: 0.4046 - val_loss: 1.5497 - val_accuracy: 0.4485\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.7166 - accuracy: 0.3947 - val_loss: 1.5784 - val_accuracy: 0.4751\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 1.7485 - accuracy: 0.3881 - val_loss: 1.5347 - val_accuracy: 0.4618\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.7192 - accuracy: 0.3980 - val_loss: 1.5619 - val_accuracy: 0.4784\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 14s 355ms/step - loss: 1.7353 - accuracy: 0.3972 - val_loss: 1.5271 - val_accuracy: 0.4751\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 13s 343ms/step - loss: 1.6748 - accuracy: 0.4171 - val_loss: 1.4076 - val_accuracy: 0.5050\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.6749 - accuracy: 0.3980 - val_loss: 1.5747 - val_accuracy: 0.4585\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 13s 351ms/step - loss: 1.6772 - accuracy: 0.4071 - val_loss: 1.4366 - val_accuracy: 0.4784\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 14s 352ms/step - loss: 1.6582 - accuracy: 0.4129 - val_loss: 1.4258 - val_accuracy: 0.4884\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 14s 353ms/step - loss: 1.6068 - accuracy: 0.4337 - val_loss: 1.4476 - val_accuracy: 0.4684\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.6428 - accuracy: 0.4320 - val_loss: 1.6022 - val_accuracy: 0.4153\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 15s 381ms/step - loss: 1.6731 - accuracy: 0.4055 - val_loss: 1.5123 - val_accuracy: 0.4684\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 14s 354ms/step - loss: 1.5826 - accuracy: 0.4362 - val_loss: 1.4387 - val_accuracy: 0.4684\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 14s 364ms/step - loss: 1.6179 - accuracy: 0.4370 - val_loss: 1.4739 - val_accuracy: 0.5050\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 14s 350ms/step - loss: 1.6666 - accuracy: 0.4320 - val_loss: 1.5910 - val_accuracy: 0.4551\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 1.6198 - accuracy: 0.4362 - val_loss: 1.5259 - val_accuracy: 0.4651\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 15s 381ms/step - loss: 1.6442 - accuracy: 0.4312 - val_loss: 1.4805 - val_accuracy: 0.4817\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 1.5889 - accuracy: 0.4420 - val_loss: 1.4885 - val_accuracy: 0.5150\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 15s 377ms/step - loss: 1.5593 - accuracy: 0.4395 - val_loss: 1.4497 - val_accuracy: 0.5083\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 1.5826 - accuracy: 0.4461 - val_loss: 1.4966 - val_accuracy: 0.4950\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 14s 364ms/step - loss: 1.5530 - accuracy: 0.4602 - val_loss: 1.4579 - val_accuracy: 0.5216\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 15s 375ms/step - loss: 1.5519 - accuracy: 0.4411 - val_loss: 1.4961 - val_accuracy: 0.4950\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 14s 359ms/step - loss: 1.5595 - accuracy: 0.4486 - val_loss: 1.4577 - val_accuracy: 0.4950\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.5682 - accuracy: 0.4403 - val_loss: 1.4045 - val_accuracy: 0.5615\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 14s 351ms/step - loss: 1.5320 - accuracy: 0.4602 - val_loss: 1.4298 - val_accuracy: 0.5183\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 14s 367ms/step - loss: 1.5496 - accuracy: 0.4502 - val_loss: 1.3646 - val_accuracy: 0.5449\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 14s 352ms/step - loss: 1.4927 - accuracy: 0.4826 - val_loss: 1.5907 - val_accuracy: 0.4751\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 14s 366ms/step - loss: 1.5215 - accuracy: 0.4635 - val_loss: 1.4422 - val_accuracy: 0.5183\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.5882 - accuracy: 0.4287 - val_loss: 1.3946 - val_accuracy: 0.5183\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 1.5748 - accuracy: 0.4428 - val_loss: 1.4312 - val_accuracy: 0.4983\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 14s 374ms/step - loss: 1.5249 - accuracy: 0.4619 - val_loss: 1.4275 - val_accuracy: 0.5249\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 14s 370ms/step - loss: 1.5049 - accuracy: 0.4710 - val_loss: 1.4238 - val_accuracy: 0.4884\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 15s 378ms/step - loss: 1.5577 - accuracy: 0.4378 - val_loss: 1.4854 - val_accuracy: 0.4817\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 14s 357ms/step - loss: 1.4865 - accuracy: 0.4677 - val_loss: 1.3682 - val_accuracy: 0.5249\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 13s 345ms/step - loss: 1.5056 - accuracy: 0.4867 - val_loss: 1.3720 - val_accuracy: 0.4950\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.5281 - accuracy: 0.4594 - val_loss: 1.3824 - val_accuracy: 0.5183\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 13s 333ms/step - loss: 1.4730 - accuracy: 0.4668 - val_loss: 1.3594 - val_accuracy: 0.5116\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 1.4619 - accuracy: 0.4693 - val_loss: 1.4242 - val_accuracy: 0.5116\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.4957 - accuracy: 0.4851 - val_loss: 1.4720 - val_accuracy: 0.5216\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.4772 - accuracy: 0.4619 - val_loss: 1.3851 - val_accuracy: 0.5050\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4669 - accuracy: 0.4867 - val_loss: 1.3918 - val_accuracy: 0.5249\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.5413 - accuracy: 0.4527 - val_loss: 1.4123 - val_accuracy: 0.4983\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.4673 - accuracy: 0.4834 - val_loss: 1.3739 - val_accuracy: 0.5382\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.4389 - accuracy: 0.4967 - val_loss: 1.3776 - val_accuracy: 0.5282\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4573 - accuracy: 0.4942 - val_loss: 1.4148 - val_accuracy: 0.5183\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 1.4634 - accuracy: 0.4768 - val_loss: 1.3287 - val_accuracy: 0.5415\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 1.4625 - accuracy: 0.4685 - val_loss: 1.4062 - val_accuracy: 0.5183\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4508 - accuracy: 0.4718 - val_loss: 1.3918 - val_accuracy: 0.5216\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4477 - accuracy: 0.4635 - val_loss: 1.3319 - val_accuracy: 0.5282\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 1.4531 - accuracy: 0.4751 - val_loss: 1.2751 - val_accuracy: 0.5415\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 13s 338ms/step - loss: 1.4285 - accuracy: 0.5008 - val_loss: 1.3426 - val_accuracy: 0.5083\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.4703 - accuracy: 0.4743 - val_loss: 1.2477 - val_accuracy: 0.5515\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.4208 - accuracy: 0.4992 - val_loss: 1.3125 - val_accuracy: 0.5449\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.3965 - accuracy: 0.5041 - val_loss: 1.3950 - val_accuracy: 0.5316\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 13s 348ms/step - loss: 1.3710 - accuracy: 0.5058 - val_loss: 1.3208 - val_accuracy: 0.5482\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.3838 - accuracy: 0.5083 - val_loss: 1.2924 - val_accuracy: 0.5316\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.4342 - accuracy: 0.4801 - val_loss: 1.3761 - val_accuracy: 0.5017\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 1.3980 - accuracy: 0.4925 - val_loss: 1.2944 - val_accuracy: 0.5482\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 1.3955 - accuracy: 0.4983 - val_loss: 1.2432 - val_accuracy: 0.5581\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 13s 346ms/step - loss: 1.4234 - accuracy: 0.5141 - val_loss: 1.2607 - val_accuracy: 0.5249\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 13s 342ms/step - loss: 1.3930 - accuracy: 0.4934 - val_loss: 1.2846 - val_accuracy: 0.5449\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 1.4331 - accuracy: 0.4925 - val_loss: 1.2727 - val_accuracy: 0.5714\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 1.4239 - accuracy: 0.5017 - val_loss: 1.3233 - val_accuracy: 0.5282\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 1.4418 - accuracy: 0.4867 - val_loss: 1.3984 - val_accuracy: 0.5282\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 13s 340ms/step - loss: 1.4564 - accuracy: 0.4900 - val_loss: 1.3890 - val_accuracy: 0.5183\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 1.4179 - accuracy: 0.5066 - val_loss: 1.2621 - val_accuracy: 0.5316\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 1.3568 - accuracy: 0.5108 - val_loss: 1.2494 - val_accuracy: 0.5847\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 2103s 57s/step - loss: 1.3438 - accuracy: 0.5149 - val_loss: 1.3353 - val_accuracy: 0.5116\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 16s 387ms/step - loss: 1.2986 - accuracy: 0.5605 - val_loss: 1.2731 - val_accuracy: 0.5714\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 1.3722 - accuracy: 0.5216 - val_loss: 1.3647 - val_accuracy: 0.5648\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 9s 240ms/step - loss: 1.3507 - accuracy: 0.5307 - val_loss: 1.2512 - val_accuracy: 0.5814\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 9s 232ms/step - loss: 1.3434 - accuracy: 0.5290 - val_loss: 1.2607 - val_accuracy: 0.5548\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 8s 198ms/step - loss: 1.4030 - accuracy: 0.5025 - val_loss: 1.2596 - val_accuracy: 0.5415\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 8s 214ms/step - loss: 1.3205 - accuracy: 0.5116 - val_loss: 1.4122 - val_accuracy: 0.5648\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 8s 200ms/step - loss: 1.2738 - accuracy: 0.5381 - val_loss: 1.2800 - val_accuracy: 0.5648\n",
      "10/10 [==============================] - 1s 48ms/step\n",
      "Cross-validation results:\n",
      "Mean validation accuracy: 0.5673 (+/- 0.0277)\n"
     ]
    }
   ],
   "source": [
    "##LeNet with data augmentation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the number of folds for cross-validation and other hyperparameters\n",
    "n_folds = 5  # Number of folds for cross-validation\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_deep = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "val_accuracy_per_fold_augm = []\n",
    "\n",
    "# Perform cross-validation using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(images, labels_deep)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train_fold = images[train_index]\n",
    "    y_train_fold = labels_deep[train_index]\n",
    "    X_val_fold = images[val_index]\n",
    "    y_val_fold = labels_deep[val_index]\n",
    "\n",
    "    # Encode the labels\n",
    "    #label_encoder = LabelEncoder()\n",
    "    #y_train_fold = label_encoder.fit_transform(y_train_fold)\n",
    "    #y_val_fold = label_encoder.fit_transform(y_val_fold)\n",
    "\n",
    "    # Define the input shape and number of classes\n",
    "    input_shape = X_train_fold.shape[1:]\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    # Create the LeNet model\n",
    "    model = create_LeNet_model(input_shape, num_classes)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(datagen.flow(X_train_fold, y_train_fold, batch_size=batch_size), epochs=epochs, validation_data=(X_val_fold, y_val_fold))\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    y_val_pred_augm = model.predict(X_val_fold)\n",
    "    y_val_pred_labels_augm = np.argmax(y_val_pred_augm, axis=1)\n",
    "    y_val_true_labels_augm = y_val_fold\n",
    "    #np.argmax(np.reshape(y_val_fold, (-1, 1)), axis=1)\n",
    "    val_accuracy_augm = accuracy_score(y_val_true_labels_augm, y_val_pred_labels_augm)\n",
    "\n",
    "    val_accuracy_per_fold_augm.append(val_accuracy_augm)\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the evaluation metrics across folds\n",
    "print(\"Cross-validation results:\")\n",
    "print(f\"Mean validation accuracy: {np.mean(val_accuracy_per_fold_augm):.4f} (+/- {np.std(val_accuracy_per_fold_augm):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store the training and validation accuracy and loss\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Adam Sandler', 'Alec Baldwin', 'Angelina Jolie', 'Anna Kournikova', 'Ashton Kutcher', 'Avril Lavigne', 'Barack Obama', 'Ben Affleck', 'Beyonce Knowles'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no significant difference between the two approaches.\n"
     ]
    }
   ],
   "source": [
    "#Compare the results with and without the data augmentation\n",
    "\n",
    "## Detailed comparison : LeNet with and without data augmentation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from scipy.stats import ttest_rel\n",
    "from collections import Counter\n",
    "\n",
    "# Assume you have obtained the predictions and true labels for each approach\n",
    "data_augm_prediction = y_val_pred_labels_augm\n",
    "deep_learning_predictions = y_val_pred_labels\n",
    "true_labels_deep_learning = y_val_true_labels\n",
    "true_labels_data_augm = y_val_true_labels_augm\n",
    "\n",
    "# Compute the confusion matrices\n",
    "traditional_cm = confusion_matrix(y_val_true_labels_augm, y_val_pred_labels_augm)\n",
    "deep_learning_cm = confusion_matrix(y_val_true_labels, y_val_pred_labels)\n",
    "\n",
    "# Plot the confusion matrices\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "axes[0].imshow(traditional_cm, cmap='Blues')\n",
    "axes[0].set_title('Deep Learning Data AUgmentation')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "axes[1].imshow(deep_learning_cm, cmap='Blues')\n",
    "axes[1].set_title('Deep Learning')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Plot Class\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(labels, bins = 9)\n",
    "plt.show()\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "traditional_metrics = precision_recall_fscore_support(true_labels_data_augm, data_augm_prediction, average=None)\n",
    "deep_learning_metrics = precision_recall_fscore_support(true_labels_deep_learning, deep_learning_predictions, average=None)\n",
    "\n",
    "# Plot class-specific metrics\n",
    "classes = Counter(labels)\n",
    "print(classes.keys())\n",
    "x = np.arange(len(classes.keys()))\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "ax.bar(x - width/2, traditional_metrics[0], width, label='Data Augmentation')\n",
    "ax.bar(x + width/2, deep_learning_metrics[0], width, label='Deep Learning')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision by Class')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Perform statistical test\n",
    "_, p_value = ttest_rel(traditional_metrics[0], deep_learning_metrics[0])\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the two approaches.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the two approaches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 50, 50, 96)   14208       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 24, 24, 96)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 24, 24, 16)   1552        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 24, 24, 64)   1088        ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 24, 24, 64)   9280        ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 24, 24, 128)  0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 24, 24, 16)   2064        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 24, 24, 64)   1088        ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 24, 24, 64)   9280        ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 24, 24, 128)  0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 24, 24, 32)   4128        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 24, 24, 128)  4224        ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 24, 24, 128)  36992       ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 24, 24, 256)  0           ['conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 256)  0          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 11, 11, 32)   8224        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 11, 11, 128)  4224        ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 11, 11, 128)  36992       ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 11, 11, 256)  0           ['conv2d_11[0][0]',              \n",
      "                                                                  'conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 11, 11, 48)   12336       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 11, 11, 192)  9408        ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 11, 11, 192)  83136       ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 11, 11, 384)  0           ['conv2d_14[0][0]',              \n",
      "                                                                  'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 11, 11, 48)   18480       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 11, 11, 192)  9408        ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 11, 11, 192)  83136       ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 11, 11, 384)  0           ['conv2d_17[0][0]',              \n",
      "                                                                  'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 11, 11, 64)   24640       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 11, 11, 256)  16640       ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 11, 11, 256)  147712      ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 11, 11, 512)  0           ['conv2d_20[0][0]',              \n",
      "                                                                  'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 11, 11, 1000  513000      ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1000)        0           ['conv2d_22[0][0]']              \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1000)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,051,240\n",
      "Trainable params: 1,051,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Squeezenet structure\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, GlobalAveragePooling2D, Activation\n",
    "\n",
    "def fire_module(x, squeeze, expand):\n",
    "    squeezed = Conv2D(squeeze, (1, 1), activation='relu')(x)\n",
    "    expand1x1 = Conv2D(expand, (1, 1), activation='relu')(squeezed)\n",
    "    expand3x3 = Conv2D(expand, (3, 3), padding='same', activation='relu')(squeezed)\n",
    "    return concatenate([expand1x1, expand3x3])\n",
    "\n",
    "def SqueezeNet(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(96, (7, 7), strides=(2, 2), activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = fire_module(x, 16, 64)\n",
    "    x = fire_module(x, 16, 64)\n",
    "    x = fire_module(x, 32, 128)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = fire_module(x, 32, 128)\n",
    "    x = fire_module(x, 48, 192)\n",
    "    x = fire_module(x, 48, 192)\n",
    "    x = fire_module(x, 64, 256)\n",
    "\n",
    "    x = Conv2D(num_classes, (1, 1), activation='relu', padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "input_shape = X_train.shape[1:]  # Input image shape\n",
    "num_classes = 1000  # Number of output classes\n",
    "model = SqueezeNet(input_shape, num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 24s 499ms/step - loss: 2.4433 - accuracy: 0.1876 - val_loss: 2.1685 - val_accuracy: 0.1954\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 24s 633ms/step - loss: 2.1550 - accuracy: 0.1726 - val_loss: 2.1387 - val_accuracy: 0.1755\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 20s 535ms/step - loss: 2.1398 - accuracy: 0.1900 - val_loss: 2.1425 - val_accuracy: 0.1987\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 20s 537ms/step - loss: 2.1395 - accuracy: 0.1942 - val_loss: 2.1384 - val_accuracy: 0.1987\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 20s 529ms/step - loss: 2.1383 - accuracy: 0.2025 - val_loss: 2.1402 - val_accuracy: 0.1755\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 2.1387 - accuracy: 0.2025 - val_loss: 2.1379 - val_accuracy: 0.1987\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 20s 527ms/step - loss: 2.1386 - accuracy: 0.1917 - val_loss: 2.1439 - val_accuracy: 0.1987\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 2.1386 - accuracy: 0.1983 - val_loss: 2.1415 - val_accuracy: 0.1987\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 20s 525ms/step - loss: 2.1391 - accuracy: 0.1826 - val_loss: 2.1376 - val_accuracy: 0.1987\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 20s 527ms/step - loss: 2.1391 - accuracy: 0.1950 - val_loss: 2.1379 - val_accuracy: 0.1987\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 20s 522ms/step - loss: 2.1380 - accuracy: 0.1983 - val_loss: 2.1380 - val_accuracy: 0.1987\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 20s 524ms/step - loss: 2.1389 - accuracy: 0.1983 - val_loss: 2.1376 - val_accuracy: 0.1987\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 2.1377 - accuracy: 0.1959 - val_loss: 2.1379 - val_accuracy: 0.1987\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 21s 550ms/step - loss: 2.1384 - accuracy: 0.1983 - val_loss: 2.1382 - val_accuracy: 0.1987\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 20s 536ms/step - loss: 2.1382 - accuracy: 0.1983 - val_loss: 2.1423 - val_accuracy: 0.1987\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 20s 531ms/step - loss: 2.1387 - accuracy: 0.1983 - val_loss: 2.1378 - val_accuracy: 0.1987\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 18s 483ms/step - loss: 2.1387 - accuracy: 0.1983 - val_loss: 2.1379 - val_accuracy: 0.1987\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 20s 522ms/step - loss: 2.1374 - accuracy: 0.1983 - val_loss: 2.1377 - val_accuracy: 0.1987\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 20s 515ms/step - loss: 2.1759 - accuracy: 0.2000 - val_loss: 2.1378 - val_accuracy: 0.1987\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 20s 516ms/step - loss: 2.1374 - accuracy: 0.1983 - val_loss: 2.1378 - val_accuracy: 0.1987\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 20s 518ms/step - loss: 2.1372 - accuracy: 0.1983 - val_loss: 2.1402 - val_accuracy: 0.1987\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 2.1387 - accuracy: 0.1934 - val_loss: 2.1398 - val_accuracy: 0.1987\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 23s 599ms/step - loss: 2.1380 - accuracy: 0.1959 - val_loss: 2.1375 - val_accuracy: 0.1987\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 20s 539ms/step - loss: 2.5318 - accuracy: 0.1992 - val_loss: 2.1349 - val_accuracy: 0.2086\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 17s 455ms/step - loss: 2.1252 - accuracy: 0.1959 - val_loss: 2.1235 - val_accuracy: 0.1987\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 17s 440ms/step - loss: 2.1220 - accuracy: 0.1983 - val_loss: 2.1243 - val_accuracy: 0.1987\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 17s 458ms/step - loss: 2.1219 - accuracy: 0.1917 - val_loss: 2.1245 - val_accuracy: 0.1987\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 17s 446ms/step - loss: 2.1228 - accuracy: 0.1967 - val_loss: 2.1256 - val_accuracy: 0.1987\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 17s 443ms/step - loss: 2.1225 - accuracy: 0.1959 - val_loss: 2.1245 - val_accuracy: 0.1987\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 17s 444ms/step - loss: 2.1217 - accuracy: 0.1892 - val_loss: 2.1250 - val_accuracy: 0.1987\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 18s 483ms/step - loss: 2.1222 - accuracy: 0.1983 - val_loss: 2.1236 - val_accuracy: 0.1987\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 19s 488ms/step - loss: 2.1226 - accuracy: 0.1942 - val_loss: 2.1236 - val_accuracy: 0.1987\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 2.1224 - accuracy: 0.1942 - val_loss: 2.1233 - val_accuracy: 0.1987\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 21s 549ms/step - loss: 2.1179 - accuracy: 0.2025 - val_loss: 2.0854 - val_accuracy: 0.1987\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 2.1278 - accuracy: 0.1892 - val_loss: 2.1250 - val_accuracy: 0.1755\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 20s 520ms/step - loss: 2.1224 - accuracy: 0.1892 - val_loss: 2.1242 - val_accuracy: 0.2384\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 20s 522ms/step - loss: 2.1237 - accuracy: 0.1859 - val_loss: 2.1244 - val_accuracy: 0.1987\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 2.1220 - accuracy: 0.1925 - val_loss: 2.1236 - val_accuracy: 0.1987\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 20s 519ms/step - loss: 2.1215 - accuracy: 0.1983 - val_loss: 2.1244 - val_accuracy: 0.1987\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 20s 527ms/step - loss: 2.1230 - accuracy: 0.1884 - val_loss: 2.1248 - val_accuracy: 0.1987\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 2.1172 - accuracy: 0.1992 - val_loss: 2.1249 - val_accuracy: 0.1788\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 21s 553ms/step - loss: 2.1190 - accuracy: 0.2332 - val_loss: 2.0878 - val_accuracy: 0.2682\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 20s 532ms/step - loss: 2.0783 - accuracy: 0.2813 - val_loss: 2.0613 - val_accuracy: 0.3311\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 22s 571ms/step - loss: 2.0388 - accuracy: 0.2855 - val_loss: 1.9874 - val_accuracy: 0.3079\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 24s 648ms/step - loss: 2.0348 - accuracy: 0.3187 - val_loss: 2.0103 - val_accuracy: 0.3013\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 21s 549ms/step - loss: 1.9648 - accuracy: 0.3203 - val_loss: 2.0306 - val_accuracy: 0.3344\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 19s 502ms/step - loss: 1.9796 - accuracy: 0.3353 - val_loss: 1.9589 - val_accuracy: 0.3444\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 20s 521ms/step - loss: 1.9062 - accuracy: 0.3469 - val_loss: 1.8563 - val_accuracy: 0.3510\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 19s 510ms/step - loss: 1.8793 - accuracy: 0.3618 - val_loss: 1.8886 - val_accuracy: 0.3642\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 23s 596ms/step - loss: 1.8510 - accuracy: 0.3701 - val_loss: 1.8401 - val_accuracy: 0.3742\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 20s 534ms/step - loss: 1.8472 - accuracy: 0.3751 - val_loss: 1.8715 - val_accuracy: 0.3510\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 1.7988 - accuracy: 0.4075 - val_loss: 1.7965 - val_accuracy: 0.3609\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 21s 540ms/step - loss: 1.7126 - accuracy: 0.4174 - val_loss: 1.7416 - val_accuracy: 0.3841\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 21s 550ms/step - loss: 1.7239 - accuracy: 0.4490 - val_loss: 1.7293 - val_accuracy: 0.4272\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 21s 553ms/step - loss: 1.6668 - accuracy: 0.4539 - val_loss: 1.9411 - val_accuracy: 0.3146\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 20s 539ms/step - loss: 1.6596 - accuracy: 0.4390 - val_loss: 1.5906 - val_accuracy: 0.4868\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 20s 520ms/step - loss: 1.5041 - accuracy: 0.4855 - val_loss: 1.5320 - val_accuracy: 0.4636\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 20s 516ms/step - loss: 1.4299 - accuracy: 0.5187 - val_loss: 1.6070 - val_accuracy: 0.4172\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 21s 563ms/step - loss: 1.4096 - accuracy: 0.5137 - val_loss: 1.4672 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 21s 545ms/step - loss: 1.3360 - accuracy: 0.5452 - val_loss: 1.7793 - val_accuracy: 0.4371\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 23s 604ms/step - loss: 1.3277 - accuracy: 0.5568 - val_loss: 1.5828 - val_accuracy: 0.4139\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 22s 587ms/step - loss: 1.2908 - accuracy: 0.5527 - val_loss: 1.4289 - val_accuracy: 0.5132\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 21s 547ms/step - loss: 1.2435 - accuracy: 0.5635 - val_loss: 1.4692 - val_accuracy: 0.5033\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 23s 609ms/step - loss: 1.2128 - accuracy: 0.5817 - val_loss: 1.3766 - val_accuracy: 0.5298\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 21s 554ms/step - loss: 1.1676 - accuracy: 0.5768 - val_loss: 1.5813 - val_accuracy: 0.4868\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 23s 616ms/step - loss: 1.1837 - accuracy: 0.5867 - val_loss: 1.6378 - val_accuracy: 0.4238\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 21s 550ms/step - loss: 1.1245 - accuracy: 0.6058 - val_loss: 1.6437 - val_accuracy: 0.4834\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 23s 597ms/step - loss: 1.1162 - accuracy: 0.6041 - val_loss: 1.5011 - val_accuracy: 0.5397\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 20s 535ms/step - loss: 1.0520 - accuracy: 0.6415 - val_loss: 1.4424 - val_accuracy: 0.4967\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 20s 532ms/step - loss: 0.9545 - accuracy: 0.6556 - val_loss: 1.6385 - val_accuracy: 0.5166\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 22s 586ms/step - loss: 0.9376 - accuracy: 0.6606 - val_loss: 1.5042 - val_accuracy: 0.5166\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 0.9226 - accuracy: 0.6813 - val_loss: 1.5362 - val_accuracy: 0.5265\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 20s 524ms/step - loss: 0.8511 - accuracy: 0.7154 - val_loss: 1.7601 - val_accuracy: 0.5066\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 21s 541ms/step - loss: 0.8575 - accuracy: 0.7046 - val_loss: 1.8850 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 20s 516ms/step - loss: 0.8628 - accuracy: 0.7012 - val_loss: 1.8083 - val_accuracy: 0.5563\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 20s 535ms/step - loss: 0.7637 - accuracy: 0.7411 - val_loss: 1.3953 - val_accuracy: 0.5563\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 20s 524ms/step - loss: 0.7479 - accuracy: 0.7320 - val_loss: 2.1255 - val_accuracy: 0.4570\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 21s 544ms/step - loss: 0.7509 - accuracy: 0.7419 - val_loss: 1.5134 - val_accuracy: 0.5430\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 20s 523ms/step - loss: 0.7217 - accuracy: 0.7643 - val_loss: 1.7650 - val_accuracy: 0.5331\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 19s 498ms/step - loss: 0.6675 - accuracy: 0.7751 - val_loss: 2.2813 - val_accuracy: 0.4404\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 20s 519ms/step - loss: 0.6372 - accuracy: 0.7643 - val_loss: 1.7520 - val_accuracy: 0.5894\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.6531 - accuracy: 0.7801 - val_loss: 1.9133 - val_accuracy: 0.5464\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 23s 608ms/step - loss: 0.5494 - accuracy: 0.8041 - val_loss: 1.6327 - val_accuracy: 0.5430\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 18s 484ms/step - loss: 0.5506 - accuracy: 0.8066 - val_loss: 2.0465 - val_accuracy: 0.5728\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.6364 - accuracy: 0.8066 - val_loss: 2.0766 - val_accuracy: 0.5464\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 23s 618ms/step - loss: 0.4869 - accuracy: 0.8332 - val_loss: 2.1219 - val_accuracy: 0.5629\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 22s 568ms/step - loss: 0.5425 - accuracy: 0.8249 - val_loss: 2.4163 - val_accuracy: 0.4934\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 20s 516ms/step - loss: 0.5265 - accuracy: 0.8315 - val_loss: 1.7818 - val_accuracy: 0.4967\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.5150 - accuracy: 0.8407 - val_loss: 2.6064 - val_accuracy: 0.4967\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.5351 - accuracy: 0.8299 - val_loss: 1.8012 - val_accuracy: 0.5762\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 23s 596ms/step - loss: 0.4612 - accuracy: 0.8481 - val_loss: 1.7704 - val_accuracy: 0.5397\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 23s 607ms/step - loss: 0.4244 - accuracy: 0.8747 - val_loss: 1.9773 - val_accuracy: 0.5662\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 20s 535ms/step - loss: 0.4570 - accuracy: 0.8664 - val_loss: 2.3247 - val_accuracy: 0.5364\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 0.3825 - accuracy: 0.8813 - val_loss: 2.6790 - val_accuracy: 0.5265\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 21s 543ms/step - loss: 0.4751 - accuracy: 0.8647 - val_loss: 2.1943 - val_accuracy: 0.5364\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 20s 539ms/step - loss: 0.3182 - accuracy: 0.9012 - val_loss: 3.1219 - val_accuracy: 0.4901\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 20s 519ms/step - loss: 0.4602 - accuracy: 0.8631 - val_loss: 2.3722 - val_accuracy: 0.5828\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 20s 529ms/step - loss: 0.3249 - accuracy: 0.9012 - val_loss: 2.4207 - val_accuracy: 0.5497\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 19s 513ms/step - loss: 0.3988 - accuracy: 0.8929 - val_loss: 2.7427 - val_accuracy: 0.5265\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 18s 480ms/step - loss: 0.4095 - accuracy: 0.8880 - val_loss: 2.8009 - val_accuracy: 0.5331\n",
      "10/10 [==============================] - 3s 131ms/step\n",
      "Fold 2\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 25s 520ms/step - loss: 2.2797 - accuracy: 0.1743 - val_loss: 2.1557 - val_accuracy: 0.1788\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 22s 579ms/step - loss: 2.1531 - accuracy: 0.1817 - val_loss: 2.1381 - val_accuracy: 0.1954\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 23s 608ms/step - loss: 2.1372 - accuracy: 0.1884 - val_loss: 2.1366 - val_accuracy: 0.1788\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 21s 545ms/step - loss: 2.2264 - accuracy: 0.1909 - val_loss: 2.1356 - val_accuracy: 0.1954\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 21s 545ms/step - loss: 2.1202 - accuracy: 0.1925 - val_loss: 2.1124 - val_accuracy: 0.1954\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 17s 440ms/step - loss: 2.1965 - accuracy: 0.1992 - val_loss: 2.1159 - val_accuracy: 0.1954\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 20s 520ms/step - loss: 2.1096 - accuracy: 0.2083 - val_loss: 2.1017 - val_accuracy: 0.2086\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 19s 500ms/step - loss: 2.0935 - accuracy: 0.2050 - val_loss: 2.0887 - val_accuracy: 0.1987\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 18s 476ms/step - loss: 2.0733 - accuracy: 0.2299 - val_loss: 2.4069 - val_accuracy: 0.2152\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 16s 433ms/step - loss: 2.0805 - accuracy: 0.2332 - val_loss: 2.0245 - val_accuracy: 0.2583\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 16s 432ms/step - loss: 2.0308 - accuracy: 0.2382 - val_loss: 2.0154 - val_accuracy: 0.2715\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 16s 431ms/step - loss: 2.0607 - accuracy: 0.2332 - val_loss: 2.0353 - val_accuracy: 0.2715\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 16s 431ms/step - loss: 2.0462 - accuracy: 0.2349 - val_loss: 1.9644 - val_accuracy: 0.3046\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 16s 431ms/step - loss: 2.0041 - accuracy: 0.2722 - val_loss: 2.0259 - val_accuracy: 0.2947\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 16s 430ms/step - loss: 1.9819 - accuracy: 0.2846 - val_loss: 1.9607 - val_accuracy: 0.2748\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 16s 432ms/step - loss: 1.9605 - accuracy: 0.3004 - val_loss: 1.9015 - val_accuracy: 0.3245\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 16s 431ms/step - loss: 1.9142 - accuracy: 0.3187 - val_loss: 1.8767 - val_accuracy: 0.3245\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 1.9164 - accuracy: 0.3170 - val_loss: 1.8701 - val_accuracy: 0.3212\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 21s 558ms/step - loss: 1.8913 - accuracy: 0.3402 - val_loss: 1.8601 - val_accuracy: 0.3477\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 21s 547ms/step - loss: 1.8722 - accuracy: 0.3394 - val_loss: 1.9879 - val_accuracy: 0.2980\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 20s 527ms/step - loss: 1.8170 - accuracy: 0.3577 - val_loss: 2.1163 - val_accuracy: 0.3146\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 20s 529ms/step - loss: 1.8183 - accuracy: 0.3485 - val_loss: 2.0846 - val_accuracy: 0.3278\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 20s 540ms/step - loss: 1.7855 - accuracy: 0.3743 - val_loss: 1.7910 - val_accuracy: 0.3444\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 21s 544ms/step - loss: 1.7412 - accuracy: 0.3884 - val_loss: 1.7483 - val_accuracy: 0.3907\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 21s 559ms/step - loss: 1.6903 - accuracy: 0.4025 - val_loss: 2.1176 - val_accuracy: 0.2848\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 21s 559ms/step - loss: 1.6449 - accuracy: 0.4207 - val_loss: 1.7902 - val_accuracy: 0.4106\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 19s 509ms/step - loss: 1.5600 - accuracy: 0.4423 - val_loss: 1.8198 - val_accuracy: 0.3940\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 23s 607ms/step - loss: 1.5400 - accuracy: 0.4415 - val_loss: 1.5902 - val_accuracy: 0.4768\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 22s 572ms/step - loss: 1.4840 - accuracy: 0.4755 - val_loss: 2.3078 - val_accuracy: 0.3046\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 19s 506ms/step - loss: 1.4783 - accuracy: 0.4747 - val_loss: 1.7438 - val_accuracy: 0.4338\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 20s 537ms/step - loss: 1.3878 - accuracy: 0.5054 - val_loss: 1.7644 - val_accuracy: 0.4305\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 20s 532ms/step - loss: 1.3564 - accuracy: 0.5062 - val_loss: 1.6215 - val_accuracy: 0.4570\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 19s 508ms/step - loss: 1.2888 - accuracy: 0.5203 - val_loss: 1.5690 - val_accuracy: 0.4338\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 21s 555ms/step - loss: 1.2652 - accuracy: 0.5394 - val_loss: 1.6649 - val_accuracy: 0.3709\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 1.2106 - accuracy: 0.5386 - val_loss: 1.5454 - val_accuracy: 0.4669\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 20s 539ms/step - loss: 1.1776 - accuracy: 0.5768 - val_loss: 1.6414 - val_accuracy: 0.4470\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 21s 544ms/step - loss: 1.1120 - accuracy: 0.5710 - val_loss: 1.6095 - val_accuracy: 0.4437\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 1.0926 - accuracy: 0.6066 - val_loss: 1.5210 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 21s 542ms/step - loss: 1.0227 - accuracy: 0.6290 - val_loss: 1.5056 - val_accuracy: 0.4834\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 20s 533ms/step - loss: 1.0014 - accuracy: 0.6307 - val_loss: 2.1552 - val_accuracy: 0.4768\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 20s 537ms/step - loss: 0.9885 - accuracy: 0.6407 - val_loss: 1.5572 - val_accuracy: 0.5364\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 20s 536ms/step - loss: 0.8939 - accuracy: 0.6722 - val_loss: 1.6054 - val_accuracy: 0.4768\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 0.8692 - accuracy: 0.6780 - val_loss: 1.8219 - val_accuracy: 0.4106\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 20s 525ms/step - loss: 0.8527 - accuracy: 0.7021 - val_loss: 1.7293 - val_accuracy: 0.5066\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 20s 516ms/step - loss: 0.7589 - accuracy: 0.7320 - val_loss: 2.1101 - val_accuracy: 0.4404\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 20s 518ms/step - loss: 0.7268 - accuracy: 0.7253 - val_loss: 1.9936 - val_accuracy: 0.4735\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 20s 539ms/step - loss: 0.7082 - accuracy: 0.7510 - val_loss: 1.6659 - val_accuracy: 0.5033\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 0.6405 - accuracy: 0.7718 - val_loss: 2.6954 - val_accuracy: 0.4272\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 20s 518ms/step - loss: 0.7082 - accuracy: 0.7402 - val_loss: 2.4285 - val_accuracy: 0.5199\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 21s 545ms/step - loss: 0.6287 - accuracy: 0.7942 - val_loss: 1.8803 - val_accuracy: 0.4868\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 21s 544ms/step - loss: 0.6003 - accuracy: 0.7950 - val_loss: 2.0410 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.5419 - accuracy: 0.8050 - val_loss: 2.2385 - val_accuracy: 0.4967\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 23s 602ms/step - loss: 0.6199 - accuracy: 0.7959 - val_loss: 2.3535 - val_accuracy: 0.5265\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 21s 544ms/step - loss: 0.4407 - accuracy: 0.8498 - val_loss: 3.0861 - val_accuracy: 0.4338\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 25s 658ms/step - loss: 0.4986 - accuracy: 0.8266 - val_loss: 2.0938 - val_accuracy: 0.4636\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.4652 - accuracy: 0.8598 - val_loss: 2.9580 - val_accuracy: 0.5033\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 0.5131 - accuracy: 0.8249 - val_loss: 1.9650 - val_accuracy: 0.5265\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 25s 656ms/step - loss: 0.5325 - accuracy: 0.8548 - val_loss: 2.4332 - val_accuracy: 0.4801\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.3839 - accuracy: 0.8805 - val_loss: 2.4448 - val_accuracy: 0.4669\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 20s 519ms/step - loss: 0.4566 - accuracy: 0.8606 - val_loss: 3.2590 - val_accuracy: 0.4636\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4769 - accuracy: 0.8697 - val_loss: 2.7559 - val_accuracy: 0.4735\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.4368 - accuracy: 0.8830 - val_loss: 1.9967 - val_accuracy: 0.5795\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 23s 615ms/step - loss: 0.3670 - accuracy: 0.9046 - val_loss: 3.4590 - val_accuracy: 0.5199\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 20s 538ms/step - loss: 0.4236 - accuracy: 0.8913 - val_loss: 6.5162 - val_accuracy: 0.4238\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.4169 - accuracy: 0.8863 - val_loss: 3.3198 - val_accuracy: 0.5099\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 24s 638ms/step - loss: 0.4171 - accuracy: 0.8755 - val_loss: 2.2952 - val_accuracy: 0.4834\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.3517 - accuracy: 0.8905 - val_loss: 4.9262 - val_accuracy: 0.3907\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 21s 545ms/step - loss: 0.3810 - accuracy: 0.9037 - val_loss: 4.3825 - val_accuracy: 0.4305\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 0.3818 - accuracy: 0.9037 - val_loss: 2.6001 - val_accuracy: 0.3907\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 20s 531ms/step - loss: 0.2956 - accuracy: 0.9079 - val_loss: 2.4886 - val_accuracy: 0.5497\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 17s 445ms/step - loss: 0.3119 - accuracy: 0.9261 - val_loss: 2.6447 - val_accuracy: 0.5596\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 17s 442ms/step - loss: 0.3127 - accuracy: 0.8979 - val_loss: 2.7413 - val_accuracy: 0.5331\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 18s 477ms/step - loss: 0.2726 - accuracy: 0.9278 - val_loss: 2.8593 - val_accuracy: 0.5563\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 20s 515ms/step - loss: 0.3012 - accuracy: 0.9361 - val_loss: 2.5509 - val_accuracy: 0.5331\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 20s 515ms/step - loss: 0.2975 - accuracy: 0.9212 - val_loss: 3.6817 - val_accuracy: 0.4934\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 20s 536ms/step - loss: 0.3487 - accuracy: 0.9087 - val_loss: 2.4428 - val_accuracy: 0.5762\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 21s 550ms/step - loss: 0.2606 - accuracy: 0.9394 - val_loss: 3.0625 - val_accuracy: 0.5331\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 20s 535ms/step - loss: 0.4231 - accuracy: 0.8921 - val_loss: 2.1235 - val_accuracy: 0.5232\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 20s 522ms/step - loss: 0.3054 - accuracy: 0.9336 - val_loss: 2.7175 - val_accuracy: 0.5497\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 21s 541ms/step - loss: 0.4114 - accuracy: 0.9170 - val_loss: 2.2096 - val_accuracy: 0.5166\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 20s 527ms/step - loss: 0.2583 - accuracy: 0.9328 - val_loss: 2.6212 - val_accuracy: 0.5596\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 20s 522ms/step - loss: 0.2707 - accuracy: 0.9378 - val_loss: 2.2141 - val_accuracy: 0.4735\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 0.2649 - accuracy: 0.9195 - val_loss: 2.8099 - val_accuracy: 0.5497\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 20s 535ms/step - loss: 0.2598 - accuracy: 0.9361 - val_loss: 3.8730 - val_accuracy: 0.3576\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.2757 - accuracy: 0.9261 - val_loss: 2.4008 - val_accuracy: 0.5497\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 20s 516ms/step - loss: 0.2423 - accuracy: 0.9502 - val_loss: 2.6491 - val_accuracy: 0.5563\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 20s 515ms/step - loss: 0.2469 - accuracy: 0.9369 - val_loss: 3.3933 - val_accuracy: 0.4801\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 20s 532ms/step - loss: 0.1828 - accuracy: 0.9502 - val_loss: 8.6040 - val_accuracy: 0.4205\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 20s 520ms/step - loss: 0.6029 - accuracy: 0.8855 - val_loss: 2.3325 - val_accuracy: 0.5331\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 20s 540ms/step - loss: 0.1583 - accuracy: 0.9535 - val_loss: 2.9763 - val_accuracy: 0.5464\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 0.2462 - accuracy: 0.9461 - val_loss: 2.4607 - val_accuracy: 0.5927\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 20s 520ms/step - loss: 0.3175 - accuracy: 0.9560 - val_loss: 2.6535 - val_accuracy: 0.4570\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 20s 530ms/step - loss: 0.0549 - accuracy: 0.9817 - val_loss: 3.4138 - val_accuracy: 0.5662\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 20s 538ms/step - loss: 0.4974 - accuracy: 0.9427 - val_loss: 2.9563 - val_accuracy: 0.5563\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 21s 543ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 3.6748 - val_accuracy: 0.5695\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 19s 510ms/step - loss: 0.5421 - accuracy: 0.9369 - val_loss: 2.3789 - val_accuracy: 0.5596\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 20s 527ms/step - loss: 0.1888 - accuracy: 0.9568 - val_loss: 2.4695 - val_accuracy: 0.5364\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 20s 519ms/step - loss: 0.1452 - accuracy: 0.9577 - val_loss: 2.7511 - val_accuracy: 0.5927\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 19s 501ms/step - loss: 0.3095 - accuracy: 0.9270 - val_loss: 2.7583 - val_accuracy: 0.5662\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 18s 483ms/step - loss: 0.3799 - accuracy: 0.9378 - val_loss: 2.6186 - val_accuracy: 0.5497\n",
      "10/10 [==============================] - 2s 115ms/step\n",
      "Fold 3\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 28s 574ms/step - loss: 2.7352 - accuracy: 0.1799 - val_loss: 2.1698 - val_accuracy: 0.1993\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 20s 520ms/step - loss: 2.1507 - accuracy: 0.2048 - val_loss: 2.1542 - val_accuracy: 0.1794\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 19s 514ms/step - loss: 2.2068 - accuracy: 0.1932 - val_loss: 2.1382 - val_accuracy: 0.1794\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 20s 522ms/step - loss: 2.1355 - accuracy: 0.1891 - val_loss: 2.1343 - val_accuracy: 0.1794\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 20s 520ms/step - loss: 2.1639 - accuracy: 0.1915 - val_loss: 2.1313 - val_accuracy: 0.1794\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 20s 519ms/step - loss: 2.1363 - accuracy: 0.1874 - val_loss: 2.1318 - val_accuracy: 0.1993\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 20s 521ms/step - loss: 2.1392 - accuracy: 0.1849 - val_loss: 2.1320 - val_accuracy: 0.1993\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 20s 525ms/step - loss: 2.3144 - accuracy: 0.1982 - val_loss: 2.1358 - val_accuracy: 0.2093\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 20s 524ms/step - loss: 2.1371 - accuracy: 0.1949 - val_loss: 2.1327 - val_accuracy: 0.1894\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 2.1358 - accuracy: 0.1940 - val_loss: 2.1316 - val_accuracy: 0.1993\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 19s 510ms/step - loss: 2.2897 - accuracy: 0.1882 - val_loss: 2.1317 - val_accuracy: 0.1993\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 20s 514ms/step - loss: 2.1362 - accuracy: 0.1940 - val_loss: 2.1315 - val_accuracy: 0.1993\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 19s 513ms/step - loss: 2.1359 - accuracy: 0.1915 - val_loss: 2.1314 - val_accuracy: 0.1993\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 19s 489ms/step - loss: 2.1359 - accuracy: 0.2023 - val_loss: 2.1298 - val_accuracy: 0.2591\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 19s 490ms/step - loss: 2.1395 - accuracy: 0.1998 - val_loss: 2.1335 - val_accuracy: 0.1794\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 18s 478ms/step - loss: 2.1251 - accuracy: 0.1841 - val_loss: 2.1112 - val_accuracy: 0.1993\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 19s 490ms/step - loss: 2.1183 - accuracy: 0.1932 - val_loss: 2.1136 - val_accuracy: 0.1993\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 19s 494ms/step - loss: 2.1173 - accuracy: 0.1982 - val_loss: 2.1134 - val_accuracy: 0.1993\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 19s 499ms/step - loss: 2.1182 - accuracy: 0.1882 - val_loss: 2.1124 - val_accuracy: 0.1993\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 19s 497ms/step - loss: 2.1168 - accuracy: 0.1907 - val_loss: 2.1103 - val_accuracy: 0.1993\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 21s 565ms/step - loss: 2.1348 - accuracy: 0.1990 - val_loss: 2.0982 - val_accuracy: 0.2724\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 18s 485ms/step - loss: 2.0674 - accuracy: 0.2579 - val_loss: 1.9567 - val_accuracy: 0.2757\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 18s 471ms/step - loss: 2.0250 - accuracy: 0.2811 - val_loss: 1.9565 - val_accuracy: 0.2957\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 18s 476ms/step - loss: 1.9439 - accuracy: 0.2944 - val_loss: 1.8576 - val_accuracy: 0.3090\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 18s 477ms/step - loss: 1.9283 - accuracy: 0.3118 - val_loss: 1.8701 - val_accuracy: 0.3189\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 20s 539ms/step - loss: 1.8691 - accuracy: 0.3308 - val_loss: 1.9297 - val_accuracy: 0.3322\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 18s 474ms/step - loss: 1.8274 - accuracy: 0.3391 - val_loss: 1.7864 - val_accuracy: 0.3588\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 18s 481ms/step - loss: 1.8225 - accuracy: 0.3317 - val_loss: 1.7772 - val_accuracy: 0.4086\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 17s 454ms/step - loss: 1.7582 - accuracy: 0.3557 - val_loss: 1.8934 - val_accuracy: 0.3223\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 17s 451ms/step - loss: 1.7124 - accuracy: 0.3814 - val_loss: 1.7437 - val_accuracy: 0.4153\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 18s 481ms/step - loss: 1.7003 - accuracy: 0.3897 - val_loss: 1.7839 - val_accuracy: 0.4053\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 18s 485ms/step - loss: 1.6627 - accuracy: 0.4337 - val_loss: 1.6227 - val_accuracy: 0.4452\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 20s 515ms/step - loss: 1.6001 - accuracy: 0.4561 - val_loss: 1.6465 - val_accuracy: 0.3887\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 18s 485ms/step - loss: 1.5430 - accuracy: 0.4619 - val_loss: 1.6461 - val_accuracy: 0.4352\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 18s 478ms/step - loss: 1.5208 - accuracy: 0.4784 - val_loss: 1.5858 - val_accuracy: 0.4385\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 18s 484ms/step - loss: 1.4916 - accuracy: 0.4925 - val_loss: 1.6170 - val_accuracy: 0.4385\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 19s 496ms/step - loss: 1.4649 - accuracy: 0.4983 - val_loss: 1.6489 - val_accuracy: 0.5083\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 19s 495ms/step - loss: 1.3890 - accuracy: 0.5315 - val_loss: 1.4148 - val_accuracy: 0.5482\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 1.3842 - accuracy: 0.5149 - val_loss: 1.4055 - val_accuracy: 0.5282\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 21s 548ms/step - loss: 1.3008 - accuracy: 0.5697 - val_loss: 1.6283 - val_accuracy: 0.4219\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 19s 488ms/step - loss: 1.2907 - accuracy: 0.5531 - val_loss: 1.4038 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 17s 443ms/step - loss: 1.1944 - accuracy: 0.5804 - val_loss: 1.3561 - val_accuracy: 0.5814\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 17s 461ms/step - loss: 1.1446 - accuracy: 0.5995 - val_loss: 1.4164 - val_accuracy: 0.5216\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 17s 449ms/step - loss: 1.1253 - accuracy: 0.6078 - val_loss: 1.3963 - val_accuracy: 0.5415\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 18s 465ms/step - loss: 1.1259 - accuracy: 0.6078 - val_loss: 1.2962 - val_accuracy: 0.5449\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 17s 437ms/step - loss: 1.0343 - accuracy: 0.6551 - val_loss: 1.5685 - val_accuracy: 0.5382\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 17s 441ms/step - loss: 1.0108 - accuracy: 0.6385 - val_loss: 2.3559 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 17s 439ms/step - loss: 0.9837 - accuracy: 0.6534 - val_loss: 1.5018 - val_accuracy: 0.5216\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 16s 435ms/step - loss: 0.9581 - accuracy: 0.6609 - val_loss: 1.2330 - val_accuracy: 0.5914\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 16s 427ms/step - loss: 0.9000 - accuracy: 0.6799 - val_loss: 1.1212 - val_accuracy: 0.6146\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 16s 433ms/step - loss: 0.8906 - accuracy: 0.6799 - val_loss: 1.4881 - val_accuracy: 0.5615\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 16s 428ms/step - loss: 0.8434 - accuracy: 0.7023 - val_loss: 1.4298 - val_accuracy: 0.5681\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 16s 427ms/step - loss: 0.8186 - accuracy: 0.7139 - val_loss: 1.5813 - val_accuracy: 0.6047\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 16s 431ms/step - loss: 0.8156 - accuracy: 0.7148 - val_loss: 1.4625 - val_accuracy: 0.5316\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 16s 433ms/step - loss: 0.7123 - accuracy: 0.7537 - val_loss: 1.8110 - val_accuracy: 0.4385\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 16s 430ms/step - loss: 0.7179 - accuracy: 0.7396 - val_loss: 1.2708 - val_accuracy: 0.6379\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 16s 431ms/step - loss: 0.6457 - accuracy: 0.7546 - val_loss: 1.4461 - val_accuracy: 0.5648\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 19s 512ms/step - loss: 0.7250 - accuracy: 0.7388 - val_loss: 1.6356 - val_accuracy: 0.4784\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.6012 - accuracy: 0.7985 - val_loss: 1.7337 - val_accuracy: 0.5581\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 14s 381ms/step - loss: 0.6120 - accuracy: 0.7811 - val_loss: 2.1971 - val_accuracy: 0.4784\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 13s 350ms/step - loss: 0.5672 - accuracy: 0.7919 - val_loss: 1.8023 - val_accuracy: 0.5714\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 0.5174 - accuracy: 0.8250 - val_loss: 1.3160 - val_accuracy: 0.6246\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 13s 333ms/step - loss: 0.5432 - accuracy: 0.8126 - val_loss: 1.6900 - val_accuracy: 0.5748\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.5548 - accuracy: 0.8126 - val_loss: 1.3585 - val_accuracy: 0.6113\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.5867 - accuracy: 0.7993 - val_loss: 1.3810 - val_accuracy: 0.5814\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 13s 331ms/step - loss: 0.4033 - accuracy: 0.8557 - val_loss: 1.6131 - val_accuracy: 0.5880\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.3961 - accuracy: 0.8541 - val_loss: 1.8848 - val_accuracy: 0.6246\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.4259 - accuracy: 0.8607 - val_loss: 1.4823 - val_accuracy: 0.6279\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.3878 - accuracy: 0.8632 - val_loss: 2.5421 - val_accuracy: 0.5249\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 13s 333ms/step - loss: 0.4087 - accuracy: 0.8624 - val_loss: 1.5194 - val_accuracy: 0.5980\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.3069 - accuracy: 0.9030 - val_loss: 1.8242 - val_accuracy: 0.6213\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 13s 333ms/step - loss: 0.4042 - accuracy: 0.8698 - val_loss: 1.4996 - val_accuracy: 0.6678\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 14s 363ms/step - loss: 0.4455 - accuracy: 0.8706 - val_loss: 1.4042 - val_accuracy: 0.6179\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 13s 352ms/step - loss: 0.4124 - accuracy: 0.8673 - val_loss: 1.5168 - val_accuracy: 0.6578\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 13s 329ms/step - loss: 0.3088 - accuracy: 0.9005 - val_loss: 1.5550 - val_accuracy: 0.6512\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 13s 351ms/step - loss: 0.2877 - accuracy: 0.9113 - val_loss: 1.4335 - val_accuracy: 0.6379\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 0.2832 - accuracy: 0.9204 - val_loss: 1.6336 - val_accuracy: 0.6013\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.2585 - accuracy: 0.9163 - val_loss: 1.9846 - val_accuracy: 0.6246\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 14s 376ms/step - loss: 1.1442 - accuracy: 0.8914 - val_loss: 1.8589 - val_accuracy: 0.6279\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 0.1895 - accuracy: 0.9362 - val_loss: 3.5851 - val_accuracy: 0.5183\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 14s 378ms/step - loss: 0.2613 - accuracy: 0.9279 - val_loss: 2.1571 - val_accuracy: 0.6146\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.6452 - accuracy: 0.8242 - val_loss: 1.8126 - val_accuracy: 0.6379\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.2191 - accuracy: 0.9494 - val_loss: 2.2224 - val_accuracy: 0.5947\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 16s 430ms/step - loss: 0.2817 - accuracy: 0.9212 - val_loss: 1.8036 - val_accuracy: 0.6412\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 0.3255 - accuracy: 0.9229 - val_loss: 2.4278 - val_accuracy: 0.5548\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 0.3141 - accuracy: 0.9221 - val_loss: 1.8404 - val_accuracy: 0.6379\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.3059 - accuracy: 0.9104 - val_loss: 1.7517 - val_accuracy: 0.6478\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 14s 376ms/step - loss: 0.3200 - accuracy: 0.9337 - val_loss: 1.6614 - val_accuracy: 0.6379\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 14s 375ms/step - loss: 0.1881 - accuracy: 0.9527 - val_loss: 2.0386 - val_accuracy: 0.6279\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 14s 377ms/step - loss: 0.2185 - accuracy: 0.9403 - val_loss: 4.1979 - val_accuracy: 0.5449\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 0.1893 - accuracy: 0.9420 - val_loss: 1.8091 - val_accuracy: 0.6645\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.2341 - accuracy: 0.9411 - val_loss: 2.3013 - val_accuracy: 0.6179\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 14s 358ms/step - loss: 0.4238 - accuracy: 0.9204 - val_loss: 2.3891 - val_accuracy: 0.5714\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.3337 - accuracy: 0.9171 - val_loss: 1.8802 - val_accuracy: 0.6379\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 15s 400ms/step - loss: 0.2699 - accuracy: 0.9320 - val_loss: 1.6460 - val_accuracy: 0.6412\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 15s 401ms/step - loss: 0.1956 - accuracy: 0.9502 - val_loss: 1.9832 - val_accuracy: 0.6578\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.3163 - accuracy: 0.9411 - val_loss: 1.7231 - val_accuracy: 0.6512\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.1503 - accuracy: 0.9585 - val_loss: 2.1506 - val_accuracy: 0.6478\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 14s 376ms/step - loss: 0.1766 - accuracy: 0.9461 - val_loss: 3.0230 - val_accuracy: 0.4784\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 15s 404ms/step - loss: 0.2906 - accuracy: 0.9328 - val_loss: 4.1238 - val_accuracy: 0.1960\n",
      "10/10 [==============================] - 1s 87ms/step\n",
      "Fold 4\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 17s 390ms/step - loss: 2.3898 - accuracy: 0.1617 - val_loss: 2.1704 - val_accuracy: 0.1794\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 2.2058 - accuracy: 0.1799 - val_loss: 2.1709 - val_accuracy: 0.1794\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 2.1725 - accuracy: 0.1774 - val_loss: 2.1670 - val_accuracy: 0.1794\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 16s 422ms/step - loss: 2.2561 - accuracy: 0.1824 - val_loss: 2.1699 - val_accuracy: 0.1794\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 18s 466ms/step - loss: 2.1795 - accuracy: 0.1824 - val_loss: 2.1669 - val_accuracy: 0.1794\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 2.1718 - accuracy: 0.1774 - val_loss: 2.1677 - val_accuracy: 0.1794\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 16s 433ms/step - loss: 2.1709 - accuracy: 0.1791 - val_loss: 3.9143 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 17s 440ms/step - loss: 2.4142 - accuracy: 0.1874 - val_loss: 2.1264 - val_accuracy: 0.1794\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 17s 439ms/step - loss: 2.1208 - accuracy: 0.1766 - val_loss: 2.1143 - val_accuracy: 0.1993\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.1341 - accuracy: 0.1924 - val_loss: 2.1106 - val_accuracy: 0.1993\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 15s 394ms/step - loss: 2.1260 - accuracy: 0.1998 - val_loss: 2.1179 - val_accuracy: 0.2492\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.1203 - accuracy: 0.2048 - val_loss: 2.1108 - val_accuracy: 0.1993\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 2.1198 - accuracy: 0.2007 - val_loss: 2.1109 - val_accuracy: 0.1993\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.1175 - accuracy: 0.1866 - val_loss: 2.1136 - val_accuracy: 0.1993\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 2.1433 - accuracy: 0.2330 - val_loss: 2.1158 - val_accuracy: 0.2658\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 2.0275 - accuracy: 0.2662 - val_loss: 2.0955 - val_accuracy: 0.2558\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 2.0179 - accuracy: 0.2786 - val_loss: 2.0990 - val_accuracy: 0.2060\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 1.9161 - accuracy: 0.2977 - val_loss: 1.8791 - val_accuracy: 0.3023\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 15s 397ms/step - loss: 1.8928 - accuracy: 0.3242 - val_loss: 1.8457 - val_accuracy: 0.3156\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 15s 394ms/step - loss: 1.8520 - accuracy: 0.3441 - val_loss: 1.8599 - val_accuracy: 0.3355\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 16s 433ms/step - loss: 1.8198 - accuracy: 0.3458 - val_loss: 1.8701 - val_accuracy: 0.3455\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 1.8106 - accuracy: 0.3682 - val_loss: 1.8816 - val_accuracy: 0.3090\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 17s 438ms/step - loss: 1.7534 - accuracy: 0.3939 - val_loss: 1.7205 - val_accuracy: 0.4086\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 17s 449ms/step - loss: 1.7447 - accuracy: 0.3955 - val_loss: 1.7307 - val_accuracy: 0.4286\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 1.7479 - accuracy: 0.4104 - val_loss: 1.6876 - val_accuracy: 0.4585\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 1.6638 - accuracy: 0.4345 - val_loss: 1.7354 - val_accuracy: 0.4086\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 1.6890 - accuracy: 0.4345 - val_loss: 1.6242 - val_accuracy: 0.4651\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 1.5517 - accuracy: 0.4760 - val_loss: 1.8372 - val_accuracy: 0.4153\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 1.5605 - accuracy: 0.4627 - val_loss: 1.9316 - val_accuracy: 0.3987\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 1.5355 - accuracy: 0.4685 - val_loss: 1.5020 - val_accuracy: 0.5116\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 1.5029 - accuracy: 0.4751 - val_loss: 1.6434 - val_accuracy: 0.4153\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 1.3859 - accuracy: 0.5133 - val_loss: 1.5557 - val_accuracy: 0.4850\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 1.3663 - accuracy: 0.5166 - val_loss: 1.4873 - val_accuracy: 0.5249\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 1.3055 - accuracy: 0.5514 - val_loss: 1.3470 - val_accuracy: 0.5282\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 1.2724 - accuracy: 0.5489 - val_loss: 1.4911 - val_accuracy: 0.4817\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 1.2324 - accuracy: 0.5697 - val_loss: 1.3796 - val_accuracy: 0.5249\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 1.1893 - accuracy: 0.5945 - val_loss: 1.4071 - val_accuracy: 0.5249\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 1.1509 - accuracy: 0.6012 - val_loss: 1.2974 - val_accuracy: 0.5548\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 1.1151 - accuracy: 0.6169 - val_loss: 1.4913 - val_accuracy: 0.5449\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 1.1158 - accuracy: 0.6235 - val_loss: 1.3089 - val_accuracy: 0.5847\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 1.0713 - accuracy: 0.6227 - val_loss: 1.2963 - val_accuracy: 0.5781\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 1.0253 - accuracy: 0.6393 - val_loss: 1.7796 - val_accuracy: 0.3887\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 1.0157 - accuracy: 0.6426 - val_loss: 1.7556 - val_accuracy: 0.4086\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 15s 404ms/step - loss: 0.9260 - accuracy: 0.6783 - val_loss: 1.5524 - val_accuracy: 0.5382\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 15s 396ms/step - loss: 0.9318 - accuracy: 0.6766 - val_loss: 1.3080 - val_accuracy: 0.5581\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 0.8760 - accuracy: 0.6965 - val_loss: 1.6137 - val_accuracy: 0.5814\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.8992 - accuracy: 0.6915 - val_loss: 1.5102 - val_accuracy: 0.5581\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 0.8260 - accuracy: 0.7181 - val_loss: 1.2987 - val_accuracy: 0.5781\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.7283 - accuracy: 0.7371 - val_loss: 1.5752 - val_accuracy: 0.5847\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.7520 - accuracy: 0.7479 - val_loss: 1.4433 - val_accuracy: 0.5880\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 0.7145 - accuracy: 0.7604 - val_loss: 1.6135 - val_accuracy: 0.5714\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 0.6854 - accuracy: 0.7570 - val_loss: 1.5136 - val_accuracy: 0.5880\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.7184 - accuracy: 0.7645 - val_loss: 1.4118 - val_accuracy: 0.6412\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 0.6032 - accuracy: 0.7993 - val_loss: 1.5715 - val_accuracy: 0.5681\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 0.5897 - accuracy: 0.7960 - val_loss: 1.6606 - val_accuracy: 0.5947\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.6327 - accuracy: 0.8101 - val_loss: 1.5651 - val_accuracy: 0.6047\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.5341 - accuracy: 0.8242 - val_loss: 1.3958 - val_accuracy: 0.6179\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.4657 - accuracy: 0.8308 - val_loss: 2.0479 - val_accuracy: 0.5648\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 15s 395ms/step - loss: 0.5139 - accuracy: 0.8375 - val_loss: 1.7251 - val_accuracy: 0.5847\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.4783 - accuracy: 0.8541 - val_loss: 1.7687 - val_accuracy: 0.5316\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.4044 - accuracy: 0.8765 - val_loss: 1.5028 - val_accuracy: 0.6146\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 15s 398ms/step - loss: 0.3754 - accuracy: 0.8748 - val_loss: 1.9623 - val_accuracy: 0.5980\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.4657 - accuracy: 0.8474 - val_loss: 1.6930 - val_accuracy: 0.6047\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 15s 401ms/step - loss: 0.3416 - accuracy: 0.8856 - val_loss: 1.9618 - val_accuracy: 0.5648\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 15s 394ms/step - loss: 0.3909 - accuracy: 0.8814 - val_loss: 2.0012 - val_accuracy: 0.5847\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 0.3571 - accuracy: 0.8997 - val_loss: 1.6342 - val_accuracy: 0.6179\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 15s 398ms/step - loss: 0.2857 - accuracy: 0.9163 - val_loss: 2.0487 - val_accuracy: 0.5847\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 15s 394ms/step - loss: 0.3141 - accuracy: 0.8872 - val_loss: 2.0361 - val_accuracy: 0.5847\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.3181 - accuracy: 0.9146 - val_loss: 2.0042 - val_accuracy: 0.5980\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.4472 - accuracy: 0.8905 - val_loss: 1.7004 - val_accuracy: 0.5980\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.2227 - accuracy: 0.9411 - val_loss: 2.0518 - val_accuracy: 0.5914\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.3847 - accuracy: 0.8922 - val_loss: 1.7754 - val_accuracy: 0.6146\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.2188 - accuracy: 0.9353 - val_loss: 2.7430 - val_accuracy: 0.5548\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 0.2510 - accuracy: 0.9204 - val_loss: 2.1697 - val_accuracy: 0.6246\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.2577 - accuracy: 0.9287 - val_loss: 2.3789 - val_accuracy: 0.6080\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 0.3484 - accuracy: 0.9096 - val_loss: 2.5373 - val_accuracy: 0.5814\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.3795 - accuracy: 0.9046 - val_loss: 1.7399 - val_accuracy: 0.5748\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 0.5846 - accuracy: 0.8715 - val_loss: 1.7095 - val_accuracy: 0.5814\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.1906 - accuracy: 0.9395 - val_loss: 2.0446 - val_accuracy: 0.6146\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.2294 - accuracy: 0.9403 - val_loss: 2.3775 - val_accuracy: 0.5847\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 15s 394ms/step - loss: 0.3754 - accuracy: 0.9138 - val_loss: 2.3586 - val_accuracy: 0.5880\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 0.1619 - accuracy: 0.9519 - val_loss: 3.4797 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 15s 404ms/step - loss: 0.2630 - accuracy: 0.9287 - val_loss: 2.2524 - val_accuracy: 0.5914\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.2092 - accuracy: 0.9395 - val_loss: 2.4690 - val_accuracy: 0.6213\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 16s 433ms/step - loss: 0.2805 - accuracy: 0.9428 - val_loss: 2.0610 - val_accuracy: 0.5880\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.2910 - accuracy: 0.9221 - val_loss: 2.0099 - val_accuracy: 0.6379\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 16s 430ms/step - loss: 0.9382 - accuracy: 0.7968 - val_loss: 1.8103 - val_accuracy: 0.6047\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 17s 441ms/step - loss: 0.2305 - accuracy: 0.9370 - val_loss: 1.5913 - val_accuracy: 0.5581\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 17s 436ms/step - loss: 0.1159 - accuracy: 0.9677 - val_loss: 2.6123 - val_accuracy: 0.6179\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.3017 - accuracy: 0.9187 - val_loss: 5.7828 - val_accuracy: 0.5349\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 0.2842 - accuracy: 0.9353 - val_loss: 2.1065 - val_accuracy: 0.6312\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.2148 - accuracy: 0.9444 - val_loss: 2.1829 - val_accuracy: 0.5814\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 0.1497 - accuracy: 0.9610 - val_loss: 2.0114 - val_accuracy: 0.6445\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.1162 - accuracy: 0.9635 - val_loss: 2.7896 - val_accuracy: 0.6512\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.2447 - accuracy: 0.9461 - val_loss: 5.6851 - val_accuracy: 0.4784\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 0.2124 - accuracy: 0.9511 - val_loss: 2.9533 - val_accuracy: 0.4784\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.1931 - accuracy: 0.9444 - val_loss: 2.9149 - val_accuracy: 0.5748\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 0.1806 - accuracy: 0.9502 - val_loss: 1.9664 - val_accuracy: 0.6545\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.2682 - accuracy: 0.9436 - val_loss: 2.0465 - val_accuracy: 0.6080\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 0.1726 - accuracy: 0.9552 - val_loss: 2.3264 - val_accuracy: 0.6013\n",
      "10/10 [==============================] - 1s 87ms/step\n",
      "Fold 5\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 18s 391ms/step - loss: 6.4500 - accuracy: 0.1758 - val_loss: 2.1865 - val_accuracy: 0.1761\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 15s 398ms/step - loss: 2.5135 - accuracy: 0.1774 - val_loss: 2.1540 - val_accuracy: 0.1761\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 2.1456 - accuracy: 0.1982 - val_loss: 2.1374 - val_accuracy: 0.1993\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 15s 394ms/step - loss: 2.1402 - accuracy: 0.1973 - val_loss: 2.1481 - val_accuracy: 0.1761\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 15s 396ms/step - loss: 2.1612 - accuracy: 0.1849 - val_loss: 2.1371 - val_accuracy: 0.2458\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 2.1392 - accuracy: 0.1866 - val_loss: 2.1427 - val_accuracy: 0.1761\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 2.1439 - accuracy: 0.1816 - val_loss: 2.1431 - val_accuracy: 0.1761\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.1385 - accuracy: 0.1907 - val_loss: 2.1373 - val_accuracy: 0.1993\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 2.1399 - accuracy: 0.1866 - val_loss: 2.1372 - val_accuracy: 0.1993\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 14s 381ms/step - loss: 2.1390 - accuracy: 0.1982 - val_loss: 2.1384 - val_accuracy: 0.1993\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 14s 382ms/step - loss: 2.1390 - accuracy: 0.1924 - val_loss: 2.1371 - val_accuracy: 0.1993\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 15s 383ms/step - loss: 2.1379 - accuracy: 0.1957 - val_loss: 2.1368 - val_accuracy: 0.1993\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 15s 385ms/step - loss: 2.1378 - accuracy: 0.1932 - val_loss: 2.1345 - val_accuracy: 0.1993\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 15s 385ms/step - loss: 2.1351 - accuracy: 0.1949 - val_loss: 2.1344 - val_accuracy: 0.1761\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 15s 385ms/step - loss: 2.1345 - accuracy: 0.1940 - val_loss: 2.1340 - val_accuracy: 0.1993\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 15s 383ms/step - loss: 2.1354 - accuracy: 0.1982 - val_loss: 2.1335 - val_accuracy: 0.1993\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 2.1356 - accuracy: 0.1924 - val_loss: 2.1333 - val_accuracy: 0.1993\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 2.1354 - accuracy: 0.1982 - val_loss: 2.1332 - val_accuracy: 0.1993\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 2.1365 - accuracy: 0.1990 - val_loss: 2.1334 - val_accuracy: 0.1993\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 2.1338 - accuracy: 0.1982 - val_loss: 2.1344 - val_accuracy: 0.1761\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.1373 - accuracy: 0.1808 - val_loss: 2.1333 - val_accuracy: 0.1993\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.1351 - accuracy: 0.1965 - val_loss: 2.1339 - val_accuracy: 0.1993\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 2.1366 - accuracy: 0.1924 - val_loss: 2.1334 - val_accuracy: 0.1993\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.1553 - accuracy: 0.1982 - val_loss: 2.1333 - val_accuracy: 0.1993\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.1350 - accuracy: 0.1932 - val_loss: 2.1344 - val_accuracy: 0.1993\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 15s 383ms/step - loss: 2.1356 - accuracy: 0.1932 - val_loss: 2.1333 - val_accuracy: 0.1993\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 2.1331 - accuracy: 0.1982 - val_loss: 2.1340 - val_accuracy: 0.1993\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 2.1645 - accuracy: 0.1891 - val_loss: 2.1328 - val_accuracy: 0.1993\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 2.1549 - accuracy: 0.1874 - val_loss: 2.1335 - val_accuracy: 0.1993\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 15s 385ms/step - loss: 2.1340 - accuracy: 0.1874 - val_loss: 2.1340 - val_accuracy: 0.1993\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 2.1722 - accuracy: 0.1907 - val_loss: 2.1321 - val_accuracy: 0.1993\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.1346 - accuracy: 0.1874 - val_loss: 2.1341 - val_accuracy: 0.1993\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 15s 396ms/step - loss: 2.1350 - accuracy: 0.1982 - val_loss: 2.1333 - val_accuracy: 0.1993\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 15s 398ms/step - loss: 2.1348 - accuracy: 0.1932 - val_loss: 2.1341 - val_accuracy: 0.1993\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.1360 - accuracy: 0.1965 - val_loss: 2.1331 - val_accuracy: 0.1993\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 2.1344 - accuracy: 0.1998 - val_loss: 2.1644 - val_accuracy: 0.1993\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 2.1378 - accuracy: 0.1940 - val_loss: 2.1340 - val_accuracy: 0.1993\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 2.1344 - accuracy: 0.1998 - val_loss: 2.1324 - val_accuracy: 0.1993\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 2.1658 - accuracy: 0.1907 - val_loss: 2.1339 - val_accuracy: 0.1993\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 2.1342 - accuracy: 0.1833 - val_loss: 2.1332 - val_accuracy: 0.1993\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 2.1346 - accuracy: 0.1949 - val_loss: 2.1332 - val_accuracy: 0.1993\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 2.1337 - accuracy: 0.2023 - val_loss: 2.1145 - val_accuracy: 0.2259\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 2.1229 - accuracy: 0.2214 - val_loss: 2.1205 - val_accuracy: 0.2525\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.1809 - accuracy: 0.2197 - val_loss: 2.1194 - val_accuracy: 0.2757\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 2.1454 - accuracy: 0.2471 - val_loss: 2.0982 - val_accuracy: 0.2392\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 15s 383ms/step - loss: 2.1011 - accuracy: 0.2421 - val_loss: 2.0990 - val_accuracy: 0.2292\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.0629 - accuracy: 0.2612 - val_loss: 2.0152 - val_accuracy: 0.2791\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.0420 - accuracy: 0.2562 - val_loss: 2.0016 - val_accuracy: 0.2890\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.0297 - accuracy: 0.2670 - val_loss: 1.9853 - val_accuracy: 0.3056\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 15s 385ms/step - loss: 2.0016 - accuracy: 0.2720 - val_loss: 1.9729 - val_accuracy: 0.2957\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 2.0070 - accuracy: 0.2604 - val_loss: 1.9588 - val_accuracy: 0.2857\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 15s 384ms/step - loss: 1.9747 - accuracy: 0.2935 - val_loss: 1.9147 - val_accuracy: 0.3189\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 2.0001 - accuracy: 0.2761 - val_loss: 1.9353 - val_accuracy: 0.3123\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 1.9438 - accuracy: 0.2919 - val_loss: 1.9174 - val_accuracy: 0.3355\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 1.8977 - accuracy: 0.3284 - val_loss: 1.9624 - val_accuracy: 0.3156\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 1.8844 - accuracy: 0.3383 - val_loss: 1.9024 - val_accuracy: 0.3488\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 1.8906 - accuracy: 0.3342 - val_loss: 1.8829 - val_accuracy: 0.3355\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 1.8908 - accuracy: 0.3333 - val_loss: 1.9874 - val_accuracy: 0.2824\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 1.9088 - accuracy: 0.3367 - val_loss: 1.8330 - val_accuracy: 0.3488\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 1.8426 - accuracy: 0.3557 - val_loss: 1.8928 - val_accuracy: 0.2890\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 15s 386ms/step - loss: 1.8293 - accuracy: 0.3516 - val_loss: 1.7996 - val_accuracy: 0.3721\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 1.8188 - accuracy: 0.3632 - val_loss: 1.7836 - val_accuracy: 0.3920\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 1.8224 - accuracy: 0.3856 - val_loss: 1.8877 - val_accuracy: 0.3588\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 1.7581 - accuracy: 0.3864 - val_loss: 1.8072 - val_accuracy: 0.3854\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 1.7537 - accuracy: 0.3972 - val_loss: 1.7605 - val_accuracy: 0.3621\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 1.6862 - accuracy: 0.3930 - val_loss: 1.6278 - val_accuracy: 0.4219\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 1.5766 - accuracy: 0.4337 - val_loss: 2.2060 - val_accuracy: 0.3090\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 1.5747 - accuracy: 0.4428 - val_loss: 1.7391 - val_accuracy: 0.3787\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 1.5651 - accuracy: 0.4453 - val_loss: 1.7025 - val_accuracy: 0.4020\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 1.4975 - accuracy: 0.4552 - val_loss: 1.7345 - val_accuracy: 0.3987\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 1.4807 - accuracy: 0.4619 - val_loss: 1.5505 - val_accuracy: 0.4618\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 1.4407 - accuracy: 0.4876 - val_loss: 1.4927 - val_accuracy: 0.4983\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 1.4046 - accuracy: 0.4950 - val_loss: 1.5743 - val_accuracy: 0.4219\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 1.3529 - accuracy: 0.5108 - val_loss: 1.4839 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 1.3039 - accuracy: 0.5415 - val_loss: 1.6085 - val_accuracy: 0.4751\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 1.2831 - accuracy: 0.5572 - val_loss: 1.5198 - val_accuracy: 0.4751\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 15s 400ms/step - loss: 1.2230 - accuracy: 0.5614 - val_loss: 1.6369 - val_accuracy: 0.4651\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 1.2213 - accuracy: 0.5904 - val_loss: 1.6591 - val_accuracy: 0.4784\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 1.1475 - accuracy: 0.6045 - val_loss: 1.4700 - val_accuracy: 0.4751\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 1.1419 - accuracy: 0.6144 - val_loss: 1.7587 - val_accuracy: 0.4053\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 1.0902 - accuracy: 0.6244 - val_loss: 1.6338 - val_accuracy: 0.4618\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 1.0569 - accuracy: 0.6335 - val_loss: 1.5941 - val_accuracy: 0.4618\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 1.0122 - accuracy: 0.6368 - val_loss: 1.4527 - val_accuracy: 0.4884\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 0.9860 - accuracy: 0.6542 - val_loss: 1.5452 - val_accuracy: 0.5282\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 15s 403ms/step - loss: 0.9887 - accuracy: 0.6559 - val_loss: 2.0039 - val_accuracy: 0.4651\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 15s 387ms/step - loss: 0.9661 - accuracy: 0.6526 - val_loss: 1.3717 - val_accuracy: 0.5847\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.8913 - accuracy: 0.6866 - val_loss: 1.7274 - val_accuracy: 0.5017\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.8339 - accuracy: 0.7181 - val_loss: 1.8422 - val_accuracy: 0.4850\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.8411 - accuracy: 0.7114 - val_loss: 1.5230 - val_accuracy: 0.5548\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.7932 - accuracy: 0.7313 - val_loss: 2.1412 - val_accuracy: 0.4850\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 15s 393ms/step - loss: 0.7983 - accuracy: 0.7231 - val_loss: 1.6658 - val_accuracy: 0.5515\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.7587 - accuracy: 0.7454 - val_loss: 1.9458 - val_accuracy: 0.4718\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 0.7463 - accuracy: 0.7488 - val_loss: 1.6063 - val_accuracy: 0.5415\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 15s 388ms/step - loss: 0.7352 - accuracy: 0.7463 - val_loss: 1.5415 - val_accuracy: 0.5515\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.6704 - accuracy: 0.7637 - val_loss: 1.6182 - val_accuracy: 0.5681\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 15s 389ms/step - loss: 0.6031 - accuracy: 0.7803 - val_loss: 1.9426 - val_accuracy: 0.5349\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.6538 - accuracy: 0.7811 - val_loss: 1.7968 - val_accuracy: 0.4950\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.5507 - accuracy: 0.7977 - val_loss: 1.6933 - val_accuracy: 0.5748\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 15s 392ms/step - loss: 0.6146 - accuracy: 0.8109 - val_loss: 2.2377 - val_accuracy: 0.5150\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 15s 395ms/step - loss: 0.5636 - accuracy: 0.8101 - val_loss: 2.1655 - val_accuracy: 0.5249\n",
      "10/10 [==============================] - 1s 87ms/step\n",
      "Cross-validation results:\n",
      "Mean validation accuracy: 0.4810 (+/- 0.1450)\n",
      "fit time 1490.037146806717\n"
     ]
    }
   ],
   "source": [
    "## Squeezenet\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Define the number of folds for cross-validation and other hyperparameters\n",
    "n_folds = 5  # Number of folds for cross-validation\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_deep = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "val_accuracy_per_fold = []\n",
    "\n",
    "# Perform cross-validation using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(images, labels_deep)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train_fold = images[train_index]\n",
    "    y_train_fold = labels_deep[train_index]\n",
    "    X_val_fold = images[val_index]\n",
    "    y_val_fold = labels_deep[val_index]\n",
    "\n",
    "    # Encode the labels\n",
    "    #label_encoder = LabelEncoder()\n",
    "    #y_train_fold = label_encoder.fit_transform(y_train_fold)\n",
    "    #y_val_fold = label_encoder.fit_transform(y_val_fold)\n",
    "\n",
    "    # Define the input shape and number of classes\n",
    "    input_shape = X_train.shape[1:]\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    # Create the LeNet model\n",
    "    model = SqueezeNet(input_shape, num_classes)\n",
    "\n",
    "    optimizer = RMSprop()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=batch_size, epochs=epochs, validation_data=(X_val_fold, y_val_fold))\n",
    "\n",
    "    fit_time = time.time() - start\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "    y_val_true_labels = y_val_fold\n",
    "    #np.argmax(np.reshape(y_val_fold, (-1, 1)), axis=1)\n",
    "    val_accuracy = accuracy_score(y_val_true_labels, y_val_pred_labels)\n",
    "\n",
    "    val_accuracy_per_fold.append(val_accuracy)\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the evaluation metrics across folds\n",
    "print(\"Cross-validation results:\")\n",
    "print(f\"Mean validation accuracy: {np.mean(val_accuracy_per_fold):.4f} (+/- {np.std(val_accuracy_per_fold):.4f})\")\n",
    "print(\"fit time\", fit_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lenet implementation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def create_LeNet_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer 1: Convolutional layer with 6 filters, 5x5 kernel, and ReLU activation\n",
    "    model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 2: Convolutional layer with 16 filters, 5x5 kernel, and ReLU activation\n",
    "    model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten the feature maps\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Layer 3: Fully connected layer with 120 units and ReLU activation\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "\n",
    "    # Layer 4: Fully connected layer with 84 units and ReLU activation\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "\n",
    "    # Layer 5: Output layer with 'num_classes' units and softmax activation\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
